from flask import Flask, jsonify, Response, stream_with_context, request, make_response
from flask_cors import CORS
import paho.mqtt.client as mqtt
import json
import threading
import queue
import time
import csv
import io
import socket
import requests
import re
from datetime import datetime, timedelta, timezone
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS
from iolink_sensor_info import extract_sensor_info_from_mqtt, get_sensor_info, sensor_device_info, get_iolink_master_info
try:
    from dateutil import parser
except ImportError:
    parser = None

app = Flask(__name__)
CORS(app)

# MQTT ì„¤ì •
MQTT_BROKER = '192.168.1.3'
MQTT_PORT = 1883
MQTT_TOPIC = 'TP3237'  # ì˜¨ë„ ì„¼ì„œ í† í”½
VIBRATION_MQTT_TOPIC = 'VVB001'  # ì§„ë™ ì„¼ì„œ í† í”½

# IO-Link IP ì„¤ì •
IOLINK_IP = '192.168.1.4'

# InfluxDB ì„¤ì •
INFLUXDB_URL = 'http://localhost:8090'
INFLUXDB_TOKEN = 'my-super-secret-auth-token'
INFLUXDB_ORG = 'my-org'
INFLUXDB_BUCKET = 'temperature_data'
VIBRATION_INFLUXDB_BUCKET = 'vibration_data'
VIBRATION_SAMPLING_INTERVAL = 1  # ìƒ˜í”Œë§ ê°„ê²© (ì´ˆ)

# MQTT ë©”ì‹œì§€ë¥¼ ì €ì¥í•  í
mqtt_queue = queue.Queue()
vibration_queue = queue.Queue()

# ìµœì‹  ì§„ë™ ë°ì´í„° ì €ì¥
latest_vibration_data = {
    'v_rms': None,
    'a_peak': None,
    'a_rms': None,
    'temperature': None,
    'crest': None,
    'device_status': None,
    'out1': False,
    'out2': False,
    'timestamp': None
}

# ì„¼ì„œ ë””ë°”ì´ìŠ¤ ì •ë³´ëŠ” iolink_sensor_info ëª¨ë“ˆì—ì„œ ê´€ë¦¬

# ë§ˆì§€ë§‰ ì €ì¥ ì‹œê°„ ì¶”ì  (ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì œì–´)
last_vibration_save_time = 0

# ë§ˆì§€ë§‰ MQTT ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œê°„ ì¶”ì  (ì§€ì—°ì‹œê°„ ê³„ì‚°ìš©)
last_mqtt_message_time = None

# InfluxDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    influx_client = InfluxDBClient(url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG)
    write_api = influx_client.write_api(write_options=SYNCHRONOUS)
    query_api = influx_client.query_api()
    print(f"âœ… InfluxDB connected: {INFLUXDB_URL}")
except Exception as e:
    print(f"âŒ InfluxDB connection error: {e}")
    influx_client = None
    write_api = None
    query_api = None

def parse_hex_to_temperature(hex_data):
    """16ì§„ìˆ˜ ë°ì´í„°ë¥¼ ì˜¨ë„ë¡œ ë³€í™˜ (ì˜ˆ: '0110' -> 27.2Â°C)"""
    try:
        # 16ì§„ìˆ˜ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
        hex_int = int(hex_data, 16)
        # ì˜¨ë„ ë³€í™˜ (ì˜ˆ: 272 -> 27.2)
        temperature = hex_int / 10.0
        return temperature
    except Exception as e:
        print(f"âŒ Error parsing hex to temperature: {e}")
        return None

# VVB001 ì§„ë™ì„¼ì„œ ë””ì½”ë”© ê´€ë ¨ ìƒìˆ˜
PDIN_PATHS = [
    '/iolinkmaster/port[4]/iolinkdevice/pdin',
    '/iolinkmaster/port[3]/iolinkdevice/pdin',
    '/iolinkmaster/port[2]/iolinkdevice/pdin',
    '/iolinkmaster/port[1]/iolinkdevice/pdin'
]

DEVICE_STATUS_MAP = {
    0: "Device is OK",
    1: "Maintenance required",
    2: "Out of specification",
    3: "Function check",
    4: "Offline",
    5: "Device not available",
    6: "No data available",
    7: "Cyclic data not available"
}

SPECIAL_VALUES = {
    32760: "OL",  # Overflow
    -32760: "UL",  # Underflow
    32764: "NoData",
    -32768: "Invalid"
}

def hex_to_bytes(hex_string):
    """16ì§„ìˆ˜ ë¬¸ìì—´ì„ ë°”ì´íŠ¸ ë°°ì—´ë¡œ ë³€í™˜"""
    try:
        return bytes.fromhex(hex_string)
    except Exception as e:
        print(f"âŒ Error converting hex to bytes: {e}")
        return None

def check_special(value):
    """íŠ¹ìˆ˜ ê°’ ì²´í¬"""
    if value in SPECIAL_VALUES:
        return SPECIAL_VALUES[value]
    return None

def to_float(value, default=None):
    """ì•ˆì „í•œ float ë³€í™˜"""
    try:
        return float(value)
    except (ValueError, TypeError):
        return default

def decode_vvb001(hex_data):
    """VVB001 ì§„ë™ì„¼ì„œ ë°ì´í„° ë””ì½”ë”© (ë¹… ì—”ë””ì•ˆ, 20ë°”ì´íŠ¸)"""
    try:
        if len(hex_data) != 40:  # 20ë°”ì´íŠ¸ = 40ì
            print(f"âš ï¸ Invalid hex data length: {len(hex_data)}, expected 40")
            return None
        
        bytes_data = hex_to_bytes(hex_data)
        if bytes_data is None or len(bytes_data) != 20:
            return None
        
        # ë¹… ì—”ë””ì•ˆ í˜•ì‹ìœ¼ë¡œ íŒŒì‹±
        # bytes[0:2]: v-RMS (signed int16)
        v_rms_raw = int.from_bytes(bytes_data[0:2], byteorder='big', signed=True)
        v_rms = v_rms_raw * 0.0001  # ìŠ¤ì¼€ì¼: 0.0001
        
        # bytes[4:6]: a-Peak (signed int16)
        a_peak_raw = int.from_bytes(bytes_data[4:6], byteorder='big', signed=True)
        a_peak = a_peak_raw * 0.1  # ìŠ¤ì¼€ì¼: 0.1
        
        # bytes[8:10]: a-RMS (signed int16)
        a_rms_raw = int.from_bytes(bytes_data[8:10], byteorder='big', signed=True)
        a_rms = a_rms_raw * 0.1  # ìŠ¤ì¼€ì¼: 0.1
        
        # bytes[10]: device status
        status_byte = bytes_data[10]
        device_status_code = (status_byte >> 4) & 0x07
        device_status = DEVICE_STATUS_MAP.get(device_status_code, f"Unknown({device_status_code})")
        out1 = bool(status_byte & 0x01)
        out2 = bool(status_byte & 0x02)
        
        # bytes[12:14]: temperature (signed int16)
        temp_raw = int.from_bytes(bytes_data[12:14], byteorder='big', signed=True)
        temperature = temp_raw * 0.1  # ìŠ¤ì¼€ì¼: 0.1
        
        # bytes[16:18]: crest (signed int16)
        crest_raw = int.from_bytes(bytes_data[16:18], byteorder='big', signed=True)
        crest = crest_raw * 0.1  # ìŠ¤ì¼€ì¼: 0.1
        
        # íŠ¹ìˆ˜ ê°’ ì²´í¬
        v_rms_special = check_special(v_rms_raw)
        a_peak_special = check_special(a_peak_raw)
        a_rms_special = check_special(a_rms_raw)
        temp_special = check_special(temp_raw)
        crest_special = check_special(crest_raw)
        
        return {
            'v_rms': v_rms if not v_rms_special else None,
            'a_peak': a_peak if not a_peak_special else None,
            'a_rms': a_rms if not a_rms_special else None,
            'temperature': temperature if not temp_special else None,
            'crest': crest if not crest_special else None,
            'device_status': device_status,
            'out1': out1,
            'out2': out2,
            'raw_values': {
                'v_rms': v_rms_raw,
                'a_peak': a_peak_raw,
                'a_rms': a_rms_raw,
                'temperature': temp_raw,
                'crest': crest_raw,
                'status_byte': status_byte
            },
            'special_values': {
                'v_rms': v_rms_special,
                'a_peak': a_peak_special,
                'a_rms': a_rms_special,
                'temperature': temp_special,
                'crest': crest_special
            }
        }
    except Exception as e:
        print(f"âŒ Error decoding VVB001 data: {e}")
        import traceback
        traceback.print_exc()
        return None

# MQTT í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
def on_connect(client, userdata, flags, rc):
    if rc == 0:
        print(f"âœ… MQTT Connected to {MQTT_BROKER}:{MQTT_PORT}")
        client.subscribe(MQTT_TOPIC)
        client.subscribe(VIBRATION_MQTT_TOPIC)
        print(f"âœ… Subscribed to topic: {MQTT_TOPIC}")
        print(f"âœ… Subscribed to topic: {VIBRATION_MQTT_TOPIC}")
    else:
        print(f"âŒ MQTT Connection failed with code {rc}")

def on_message(client, userdata, msg):
    global last_mqtt_message_time
    try:
        last_mqtt_message_time = time.time()  # ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œê°„ ê¸°ë¡
        message_str = msg.payload.decode('utf-8')
        print(f"ğŸ“¨ MQTT Message received on topic {msg.topic}: {message_str}")
        
        # JSON íŒŒì‹±
        try:
            data = json.loads(message_str)
            
            # TP3237 í† í”½ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬ (iolink êµ¬ì¡°)
            if msg.topic == 'TP3237':
                # JSONì—ì„œ 16ì§„ìˆ˜ ë°ì´í„° ì¶”ì¶œ (port[2] ì‚¬ìš©)
                payload = data.get('data', {}).get('payload', {})
                hex_data = payload.get('/iolinkmaster/port[2]/iolinkdevice/pdin', {}).get('data')
                # port[1]ë„ í™•ì¸ (í˜¸í™˜ì„±ì„ ìœ„í•´)
                if not hex_data:
                    hex_data = payload.get('/iolinkmaster/port[1]/iolinkdevice/pdin', {}).get('data')
                
                if hex_data:
                    # 16ì§„ìˆ˜ë¥¼ ì˜¨ë„ë¡œ ë³€í™˜
                    temperature = parse_hex_to_temperature(hex_data)
                    if temperature is not None:
                        print(f"ğŸŒ¡ï¸ Temperature extracted: {temperature}Â°C")
                        
                        # SSEë¡œ ì „ì†¡í•  ë°ì´í„° íì— ì¶”ê°€
                        mqtt_queue.put({'temperature': temperature, 'timestamp': time.time()})
                        
                        # InfluxDBì— ì €ì¥
                        if write_api:
                            try:
                                point = Point("temperature") \
                                    .field("value", float(temperature)) \
                                    .time(time.time_ns())
                                write_api.write(bucket=INFLUXDB_BUCKET, record=point)
                                print(f"ğŸ’¾ Saved to InfluxDB: {temperature}Â°C")
                            except Exception as e:
                                print(f"âŒ InfluxDB write error: {e}")
                                import traceback
                                traceback.print_exc()
                    else:
                        print("âš ï¸ Failed to parse hex data to temperature")
                else:
                    print("âš ï¸ Hex data not found in message structure")
                    print(f"ğŸ“‹ Message structure: {json.dumps(data, indent=2)}")
            # VVB001 ì§„ë™ì„¼ì„œ í† í”½ ì²˜ë¦¬
            elif msg.topic == VIBRATION_MQTT_TOPIC:
                payload = data.get('data', {}).get('payload', {})
                hex_data = None
                
                # MQTT ë©”ì‹œì§€ì—ì„œ ì„¼ì„œ ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶”ì¶œ ì‹œë„ (ë³„ë„ ëª¨ë“ˆ ì‚¬ìš©)
                try:
                    # ì§„ë™ì„¼ì„œëŠ” port 1ì— ì—°ê²°ë˜ì–´ ìˆìŒ (ë¡œê·¸ì—ì„œ í™•ì¸)
                    extract_sensor_info_from_mqtt(data, payload, port='1')
                except Exception as e:
                    print(f"âŒ ì„¼ì„œ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                
                # ì—¬ëŸ¬ ê²½ë¡œì—ì„œ pdin ë°ì´í„° ì°¾ê¸°
                for path in PDIN_PATHS:
                    hex_data = payload.get(path, {}).get('data')
                    if hex_data:
                        break
                
                if hex_data:
                    # VVB001 ë””ì½”ë”©
                    decoded_data = decode_vvb001(hex_data)
                    if decoded_data:
                        print(f"ğŸ“³ Vibration data decoded: v_rms={decoded_data.get('v_rms')}, a_peak={decoded_data.get('a_peak')}, a_rms={decoded_data.get('a_rms')}")
                        
                        # ìµœì‹  ë°ì´í„° ì—…ë°ì´íŠ¸
                        global latest_vibration_data
                        latest_vibration_data = {
                            **decoded_data,
                            'timestamp': time.time()
                        }
                        
                        # SSEë¡œ ì „ì†¡í•  ë°ì´í„° íì— ì¶”ê°€
                        vibration_queue.put({
                            'v_rms': decoded_data.get('v_rms'),
                            'a_peak': decoded_data.get('a_peak'),
                            'a_rms': decoded_data.get('a_rms'),
                            'temperature': decoded_data.get('temperature'),
                            'crest': decoded_data.get('crest'),
                            'timestamp': time.time()
                        })
                        
                        # InfluxDBì— ì €ì¥ (ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì ìš©)
                        save_vibration_to_influxdb(decoded_data)
                    else:
                        print("âš ï¸ Failed to decode VVB001 data")
                else:
                    print("âš ï¸ Hex data not found in VVB001 message structure")
                    print(f"ğŸ“‹ Message structure: {json.dumps(data, indent=2)}")
            else:
                # ë‹¤ë¥¸ í† í”½ì˜ ê²½ìš° ì¼ë°˜ ë¡œì§ ì‚¬ìš© (temperature, temp, value í•„ë“œ í™•ì¸)
                temp_value = data.get('temperature') or data.get('temp') or data.get('value')
                if temp_value is not None:
                    temperature = float(temp_value)
                    print(f"ğŸŒ¡ï¸ Temperature extracted: {temperature}Â°C")
                    
                    # SSEë¡œ ì „ì†¡í•  ë°ì´í„° íì— ì¶”ê°€
                    mqtt_queue.put({'temperature': temperature, 'timestamp': time.time()})
                    
                    # InfluxDBì— ì €ì¥
                    if write_api:
                        try:
                            point = Point("temperature") \
                                .field("value", float(temperature)) \
                                .time(time.time_ns())
                            write_api.write(bucket=INFLUXDB_BUCKET, record=point)
                            print(f"ğŸ’¾ Saved to InfluxDB: {temperature}Â°C")
                        except Exception as e:
                            print(f"âŒ InfluxDB write error: {e}")
                            import traceback
                            traceback.print_exc()
        except json.JSONDecodeError as e:
            print(f"âŒ JSON decode error: {e}")
            print(f"ğŸ“‹ Raw message: {message_str}")
        except Exception as e:
            print(f"âŒ Error processing message: {e}")
            import traceback
            traceback.print_exc()
    except Exception as e:
        print(f"âŒ Error in on_message: {e}")
        import traceback
        traceback.print_exc()

def on_disconnect(client, userdata, rc):
    print("ğŸ”Œ MQTT Disconnected")

# ì§„ë™ì„¼ì„œ ë°ì´í„°ë¥¼ InfluxDBì— ì €ì¥
def save_vibration_to_influxdb(decoded_data):
    """ì§„ë™ì„¼ì„œ ë°ì´í„°ë¥¼ InfluxDBì— ì €ì¥ (ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì ìš©)"""
    global last_vibration_save_time
    
    if not write_api:
        print("âš ï¸ write_api is None, cannot save vibration data to InfluxDB")
        return
    
    current_time = time.time()
    # ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì²´í¬
    if current_time - last_vibration_save_time < VIBRATION_SAMPLING_INTERVAL:
        return
    
    try:
        last_vibration_save_time = current_time
        
        point = Point("vibration") \
            .tag("sensor_type", "VVB001") \
            .field("v_rms", float(decoded_data.get('v_rms', 0)) if decoded_data.get('v_rms') is not None else 0) \
            .field("a_peak", float(decoded_data.get('a_peak', 0)) if decoded_data.get('a_peak') is not None else 0) \
            .field("a_rms", float(decoded_data.get('a_rms', 0)) if decoded_data.get('a_rms') is not None else 0) \
            .field("temperature", float(decoded_data.get('temperature', 0)) if decoded_data.get('temperature') is not None else 0) \
            .field("crest", float(decoded_data.get('crest', 0)) if decoded_data.get('crest') is not None else 0) \
            .time(time.time_ns())
        
        # ë¨¼ì € vibration_data ë²„í‚·ì— ì €ì¥ ì‹œë„
        try:
            write_api.write(bucket=VIBRATION_INFLUXDB_BUCKET, record=point)
            print(f"ğŸ’¾ Saved vibration data to InfluxDB (bucket: {VIBRATION_INFLUXDB_BUCKET}): v_rms={decoded_data.get('v_rms')}, a_peak={decoded_data.get('a_peak')}, a_rms={decoded_data.get('a_rms')}")
        except Exception as bucket_error:
            # ë²„í‚·ì´ ì—†ì„ ê²½ìš° temperature_data ë²„í‚·ì— ì €ì¥ (fallback)
            print(f"âš ï¸ Failed to write to {VIBRATION_INFLUXDB_BUCKET} bucket: {bucket_error}")
            print(f"âš ï¸ Trying to save to {INFLUXDB_BUCKET} bucket as fallback...")
            try:
                write_api.write(bucket=INFLUXDB_BUCKET, record=point)
                print(f"ğŸ’¾ Saved vibration data to {INFLUXDB_BUCKET} bucket as fallback")
            except Exception as e2:
                print(f"âŒ Fallback write also failed: {e2}")
                raise e2
    except Exception as e:
        print(f"âŒ InfluxDB vibration write error: {e}")
        import traceback
        traceback.print_exc()

# MQTT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ì—°ê²°
try:
    mqtt_client = mqtt.Client()
    mqtt_client.on_connect = on_connect
    mqtt_client.on_message = on_message
    mqtt_client.on_disconnect = on_disconnect
    # ìë™ ì¬ì—°ê²° ì„¤ì •
    mqtt_client.reconnect_delay_set(min_delay=1, max_delay=120)
except Exception as e:
    print(f"âŒ Error initializing MQTT client: {e}")
    mqtt_client = None

def connect_mqtt():
    if mqtt_client is None:
        print("âŒ MQTT client not initialized")
        return
    try:
        print(f"ğŸ”„ Attempting to connect to MQTT broker: {MQTT_BROKER}:{MQTT_PORT}")
        mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)
        mqtt_client.loop_start()
        print("ğŸ”„ MQTT loop started")
    except Exception as e:
        print(f"âŒ MQTT Connection error: {e}")
        print(f"ğŸ’¡ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê³  ì ì‹œ í›„ ìë™ìœ¼ë¡œ ì¬ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        import traceback
        traceback.print_exc()
        # ì¬ì—°ê²° ì‹œë„ (5ì´ˆ í›„)
        import threading
        def retry_connect():
            import time
            time.sleep(5)
            if mqtt_client is not None:
                try:
                    mqtt_client.reconnect()
                except:
                    pass
        threading.Thread(target=retry_connect, daemon=True).start()

# ë°±ê·¸ë¼ìš´ë“œì—ì„œ MQTT ì—°ê²°
mqtt_thread = threading.Thread(target=connect_mqtt, daemon=True)
mqtt_thread.start()

def get_server_ip():
    """ì„œë²„ì˜ ì™¸ë¶€ IP ì£¼ì†Œ ê°ì§€"""
    try:
        # ì†Œì¼“ì„ í†µí•´ ì™¸ë¶€ ì„œë²„ì— ì—°ê²°í•˜ì—¬ ë¡œì»¬ IP í™•ì¸
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        try:
            # ì™¸ë¶€ ì„œë²„ì— ì—°ê²° ì‹œë„ (ì‹¤ì œë¡œ ì—°ê²°í•˜ì§€ ì•Šê³  ë¡œì»¬ IPë§Œ í™•ì¸)
            s.connect(('8.8.8.8', 80))
            ip = s.getsockname()[0]
        except Exception:
            # ì—°ê²° ì‹¤íŒ¨ ì‹œ localhost ì‚¬ìš©
            ip = '127.0.0.1'
        finally:
            s.close()
        return ip
    except Exception as e:
        print(f"âš ï¸ IP ê°ì§€ ì‹¤íŒ¨: {e}")
        return '127.0.0.1'

@app.route('/api/system/ip', methods=['GET'])
def get_ip_info():
    """ì‹œìŠ¤í…œ IP ì •ë³´ ë°˜í™˜"""
    try:
        server_ip = get_server_ip()
        
        return jsonify({
            'current_ip': server_ip,
            'iolink_ip': IOLINK_IP
        })
    except Exception as e:
        print(f"âŒ IP ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return jsonify({
            'current_ip': '--',
            'iolink_ip': IOLINK_IP
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    return jsonify({'status': 'ok', 'message': 'Flask backend is running'})

@app.route('/api/iolink/device/info', methods=['GET'])
def get_iolink_device_info():
    """IO-Link Masterì—ì„œ ì„¼ì„œ ë””ë°”ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (MQTTì—ì„œ ì¶”ì¶œí•œ ì •ë³´ ìš°ì„  ì‚¬ìš©)"""
    try:
        port = request.args.get('port', '2', type=str)  # ê¸°ë³¸ê°’: port 2 (ì§„ë™ì„¼ì„œ)
        
        # ë¨¼ì € MQTTì—ì„œ ì¶”ì¶œí•œ ì„¼ì„œ ì •ë³´ í™•ì¸
        global sensor_device_info
        if sensor_device_info.get('connected') and sensor_device_info.get('last_updated'):
            # ìµœê·¼ 5ë¶„ ì´ë‚´ì— ì—…ë°ì´íŠ¸ëœ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if time.time() - sensor_device_info['last_updated'] < 300:
                return jsonify({
                    'port': sensor_device_info.get('port', port),
                    'connected': True,
                    'device_id': sensor_device_info.get('device_id'),
                    'vendor_id': sensor_device_info.get('vendor_id'),
                    'product_name': sensor_device_info.get('product_name'),
                    'serial_number': sensor_device_info.get('serial_number'),
                    'firmware_version': sensor_device_info.get('firmware_version'),
                    'device_name': sensor_device_info.get('device_name'),
                    'source': 'mqtt'
                })
        
        # MQTTì—ì„œ ì •ë³´ë¥¼ ëª» ê°€ì ¸ì˜¨ ê²½ìš° REST API ì‹œë„
        base_url = f'http://{IOLINK_IP}'
        
        device_info = {
            'port': port,
            'connected': False,
            'device_id': None,
            'vendor_id': None,
            'product_name': None,
            'serial_number': None,
            'firmware_version': None,
            'device_name': None,
            'error': None,
            'source': 'rest_api'
        }
        
        try:
            # ì›¹ ì¸í„°í˜ì´ìŠ¤ HTMLì—ì„œ ì„¼ì„œ ì •ë³´ íŒŒì‹±
            response = requests.get(base_url, timeout=3)
            
            if response.status_code == 200:
                html_content = response.text
                port_num = int(port)
                
                # HTML í…Œì´ë¸”ì—ì„œ í¬íŠ¸ë³„ ì„¼ì„œ ì •ë³´ íŒŒì‹±
                # í…Œì´ë¸” êµ¬ì¡°: Port | Mode | Comm. Mode | MasterCycleTime | Vendor ID | Device ID | Name | Serial
                pattern = rf'<tr><td>{port_num}</td>.*?<td[^>]*>([^<]*)</td>.*?<td[^>]*>([^<]*)</td>.*?<td[^>]*>([^<]*)</td>.*?<td[^>]*>(.*?)</td>.*?<td[^>]*>(.*?)</td>.*?<td[^>]*>(.*?)</td>.*?<td[^>]*>([^<]*)</td>'
                match = re.search(pattern, html_content, re.DOTALL)
                
                if match:
                    device_info['connected'] = True
                    # ë§¤ì¹­ëœ ê·¸ë£¹: Mode(1), Comm. Mode(2), MasterCycleTime(3), Vendor ID(4), Device ID(5), Name(6), Serial(7)
                    vendor_id = re.sub(r'<[^>]+>', '', match.group(4)).strip()
                    device_id = re.sub(r'<[^>]+>', '', match.group(5)).strip()
                    device_name = re.sub(r'<[^>]+>', '', match.group(6)).strip()
                    serial_number = re.sub(r'<[^>]+>', '', match.group(7)).strip()
                    
                    if vendor_id:
                        device_info['vendor_id'] = vendor_id
                    if device_id:
                        device_info['device_id'] = device_id
                    if device_name:
                        device_info['device_name'] = device_name
                        device_info['product_name'] = device_name
                    if serial_number:
                        device_info['serial_number'] = serial_number
                
                # ì„¼ì„œ ë””ë°”ì´ìŠ¤ì˜ íŒì›¨ì–´ ë²„ì „ì€ HTML í…Œì´ë¸”ì— ì—†ìœ¼ë¯€ë¡œ ì œê±°
                # (IO-Link Masterì˜ íŒì›¨ì–´ ë²„ì „ê³¼ í˜¼ë™ ë°©ì§€)
            
            # ê°œë³„ í•„ë“œ ì¡°íšŒ ì‹œë„ (ìœ„ì—ì„œ ì •ë³´ë¥¼ ëª» ê°€ì ¸ì˜¨ ê²½ìš°)
            if not device_info['connected']:
                field_paths = {
                    'device_id': [f'/api/v1/devices/{port}/deviceid', f'/api/devices/{port}/deviceid', f'/iolinkmaster/port[{port}]/iolinkdevice/deviceid'],
                    'vendor_id': [f'/api/v1/devices/{port}/vendorid', f'/api/devices/{port}/vendorid', f'/iolinkmaster/port[{port}]/iolinkdevice/vendorid'],
                    'product_name': [f'/api/v1/devices/{port}/productname', f'/api/devices/{port}/productname', f'/iolinkmaster/port[{port}]/iolinkdevice/productname'],
                    'serial_number': [f'/api/v1/devices/{port}/serialnumber', f'/api/devices/{port}/serialnumber', f'/iolinkmaster/port[{port}]/iolinkdevice/serialnumber'],
                    'firmware_version': [f'/api/v1/devices/{port}/firmwareversion', f'/api/devices/{port}/firmwareversion', f'/iolinkmaster/port[{port}]/iolinkdevice/firmwareversion']
                }
                
                for field, paths in field_paths.items():
                    for path in paths:
                        try:
                            response = requests.get(f'{base_url}{path}', timeout=2)
                            if response.status_code == 200:
                                device_info['connected'] = True
                                value = response.json()
                                # JSON ì‘ë‹µì´ ê°ì²´ì¸ ê²½ìš° value í•„ë“œ í™•ì¸
                                if isinstance(value, dict):
                                    device_info[field] = value.get('value') or value.get('data') or str(value)
                                else:
                                    device_info[field] = str(value)
                                break
                        except:
                            continue
                            
        except requests.exceptions.RequestException as e:
            device_info['error'] = f'IO-Link Master ì—°ê²° ì‹¤íŒ¨: {str(e)}'
        except Exception as e:
            device_info['error'] = f'ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        
        return jsonify(device_info)
    except Exception as e:
        print(f"âŒ IO-Link ë””ë°”ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'port': request.args.get('port', '2'),
            'connected': False,
            'error': str(e)
        }), 500

@app.route('/api/iolink/master/info', methods=['GET'])
def get_iolink_master_info_api():
    """IO-Link Master ìì²´ì˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        master_info = get_iolink_master_info(IOLINK_IP)
        return jsonify(master_info)
    except Exception as e:
        print(f"âŒ IO-Link Master ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'connected': False,
            'error': str(e)
        }), 500

@app.route('/api/network/status', methods=['GET'])
def network_status():
    """ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸ (MQTT, InfluxDB) ë° ì§€ì—°ì‹œê°„ ì¸¡ì •"""
    import time
    
    status = {
        'mqtt': {
            'connected': False,
            'latency': None  # ms
        },
        'influxdb': {
            'connected': False,
            'latency': None  # ms
        }
    }
    
    # MQTT ì—°ê²° ìƒíƒœ í™•ì¸ ë° ì§€ì—°ì‹œê°„ ì¸¡ì •
    if mqtt_client is not None:
        try:
            # MQTT í´ë¼ì´ì–¸íŠ¸ì˜ ì—°ê²° ìƒíƒœ í™•ì¸
            # _state ì†ì„± ì‚¬ìš© (0=ì—°ê²° ì•ˆ ë¨, 1=ì—°ê²° ì¤‘, 2=ì—°ê²°ë¨)
            mqtt_connected = False
            if hasattr(mqtt_client, '_state'):
                mqtt_state = mqtt_client._state
                mqtt_connected = mqtt_state == mqtt.mqtt_cs_connected
            elif hasattr(mqtt_client, 'is_connected'):
                mqtt_connected = mqtt_client.is_connected()
            else:
                # fallback: MQTT í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì–´ ìˆê³  loopê°€ ì‹¤í–‰ ì¤‘ì´ë©´ ì—°ê²°ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                try:
                    # _threadì™€ _stateë¥¼ í™•ì¸
                    if hasattr(mqtt_client, '_thread') and mqtt_client._thread and mqtt_client._thread.is_alive():
                        mqtt_connected = True
                except:
                    mqtt_connected = False
            
            status['mqtt']['connected'] = mqtt_connected
            
            # MQTT ì§€ì—°ì‹œê°„ ì¸¡ì • (ì—°ê²°ëœ ê²½ìš°ì—ë§Œ)
            if mqtt_connected:
                try:
                    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œê°„ê³¼ í˜„ì¬ ì‹œê°„ì˜ ì°¨ì´ë¡œ ì§€ì—°ì‹œê°„ ì¶”ì •
                    if last_mqtt_message_time is not None:
                        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ìˆ˜ì‹  í›„ ê²½ê³¼ ì‹œê°„ (ì´ˆ)
                        time_since_last_message = time.time() - last_mqtt_message_time
                        # ë©”ì‹œì§€ê°€ ìµœê·¼ì— ìˆ˜ì‹ ë˜ì—ˆë‹¤ë©´ ì§€ì—°ì‹œê°„ì´ ë‚®ì€ ê²ƒìœ¼ë¡œ ê°„ì£¼
                        # 5ì´ˆ ì´ë‚´ì— ë©”ì‹œì§€ê°€ ìˆ˜ì‹ ë˜ì—ˆë‹¤ë©´ <5msë¡œ í‘œì‹œ
                        if time_since_last_message < 5:
                            status['mqtt']['latency'] = round(time_since_last_message * 1000, 1)
                        else:
                            # ì˜¤ë˜ ì „ ë©”ì‹œì§€ë©´ ì§€ì—°ì‹œê°„ ì¸¡ì • ë¶ˆê°€
                            status['mqtt']['latency'] = None
                    elif hasattr(mqtt_client, '_sock') and mqtt_client._sock:
                        # ì†Œì¼“ì´ ì—´ë ¤ìˆì§€ë§Œ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ì—°ê²°ë§Œ ëœ ìƒíƒœ
                        status['mqtt']['latency'] = None
                    else:
                        status['mqtt']['latency'] = None
                except:
                    status['mqtt']['latency'] = None
        except Exception as e:
            print(f"âš ï¸ MQTT status check error: {e}")
            status['mqtt']['connected'] = False
            status['mqtt']['latency'] = None
    else:
        status['mqtt']['connected'] = False
        status['mqtt']['latency'] = None
    
    # InfluxDB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ì§€ì—°ì‹œê°„ ì¸¡ì •
    if influx_client is not None:
        try:
            start_time = time.time()
            is_connected = influx_client.ping()
            latency = round((time.time() - start_time) * 1000, 1)  # msë¡œ ë³€í™˜
            
            status['influxdb']['connected'] = is_connected
            status['influxdb']['latency'] = latency if is_connected else None
        except Exception as e:
            print(f"âš ï¸ InfluxDB status check error: {e}")
            status['influxdb']['connected'] = False
            status['influxdb']['latency'] = None
    else:
        status['influxdb']['connected'] = False
        status['influxdb']['latency'] = None
    
    return jsonify(status)

@app.route('/api/test', methods=['GET'])
def test():
    return jsonify({'message': 'Test endpoint working'})

@app.route('/api/mqtt/temperature', methods=['GET'])
def stream_temperature():
    """Server-Sent Eventsë¥¼ í†µí•´ ì‹¤ì‹œê°„ ì˜¨ë„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°"""
    def generate():
        try:
            while True:
                try:
                    # íì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 1ì´ˆ)
                    try:
                        data = mqtt_queue.get(timeout=1)
                        yield f"data: {json.dumps(data)}\n\n"
                    except queue.Empty:
                        # í•˜íŠ¸ë¹„íŠ¸ ì „ì†¡ (ì—°ê²° ìœ ì§€)
                        yield f"data: {json.dumps({'heartbeat': True})}\n\n"
                except GeneratorExit:
                    print("SSE connection closed by client")
                    break
                except Exception as e:
                    print(f"Error in stream: {e}")
                    import traceback
                    traceback.print_exc()
                    break
        except Exception as e:
            print(f"Fatal error in generate: {e}")
            import traceback
            traceback.print_exc()
    
    response = Response(stream_with_context(generate()), mimetype='text/event-stream')
    response.headers['Cache-Control'] = 'no-cache'
    response.headers['X-Accel-Buffering'] = 'no'
    return response

@app.route('/api/influxdb/temperature', methods=['GET'])
def get_temperature_history():
    """InfluxDBì—ì„œ ì˜¨ë„ ë°ì´í„° ì¡°íšŒ (range íŒŒë¼ë¯¸í„°ë¡œ ì‹œê°„ ë²”ìœ„ ì§€ì •)"""
    try:
        if influx_client is None:
            return jsonify({'error': 'InfluxDB not connected'}), 500
        
        # range íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: 1h)
        range_param = request.args.get('range', '1h')
        
        # ì¿¼ë¦¬ API ìƒì„±
        query_api = influx_client.query_api()
        
        # rangeì— ë”°ë¼ ì‹œì‘ ì‹œê°„ê³¼ ìœˆë„ìš° ê°„ê²© ê³„ì‚°
        now = datetime.utcnow()
        if range_param == '1h':
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        elif range_param == '6h':
            start_time = now - timedelta(hours=6)
            window_interval = '1m'
        elif range_param == '24h':
            start_time = now - timedelta(hours=24)
            window_interval = '5m'
        elif range_param == '7d':
            start_time = now - timedelta(days=7)
            window_interval = '30m'
        else:
            # ê¸°ë³¸ê°’: 1ì‹œê°„
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        
        start_time_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        # Flux ì¿¼ë¦¬ ì‘ì„± (createEmpty: trueë¡œ ì„¤ì •í•˜ì—¬ ë¹ˆ ì‹œê°„ëŒ€ë„ í¬í•¨)
        query = f'''
        from(bucket: "{INFLUXDB_BUCKET}")
          |> range(start: {start_time_str})
          |> filter(fn: (r) => r["_measurement"] == "temperature")
          |> filter(fn: (r) => r["_field"] == "value")
          |> aggregateWindow(every: {window_interval}, fn: mean, createEmpty: true)
          |> yield(name: "mean")
        '''
        
        # ì¿¼ë¦¬ ì‹¤í–‰
        result = query_api.query(org=INFLUXDB_ORG, query=query)
        
        # ë°ì´í„° íŒŒì‹±
        timestamps = []
        values = []
        
        for table in result:
            for record in table.records:
                timestamp = record.get_time().timestamp() * 1000  # JavaScript timestamp (ms)
                value = record.get_value()
                timestamps.append(timestamp)
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ nullë¡œ ì„¤ì • (ë¹ˆ ì‹œê°„ëŒ€)
                values.append(value if value is not None else None)
        
        # ì‹œê°„ìˆœ ì •ë ¬
        if timestamps and values:
            sorted_data = sorted(zip(timestamps, values))
            timestamps, values = zip(*sorted_data)
            timestamps = list(timestamps)
            values = list(values)
        
        return jsonify({
            'timestamps': timestamps,
            'values': values,
            'count': len(values)
        })
        
    except Exception as e:
        print(f"âŒ Error querying InfluxDB: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/latest/vibration', methods=['GET'])
def get_latest_vibration():
    """ìµœì‹  ì§„ë™ ë°ì´í„° ë°˜í™˜"""
    try:
        return jsonify(latest_vibration_data)
    except Exception as e:
        print(f"âŒ Error getting latest vibration: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/influxdb/vibration', methods=['GET'])
def get_vibration_history():
    """InfluxDBì—ì„œ ì§„ë™ ë°ì´í„° ì¡°íšŒ (range íŒŒë¼ë¯¸í„°ë¡œ ì‹œê°„ ë²”ìœ„ ì§€ì •)"""
    try:
        if influx_client is None:
            return jsonify({'error': 'InfluxDB not connected'}), 500
        
        # range íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: 1h)
        range_param = request.args.get('range', '1h')
        
        # ì¿¼ë¦¬ API ìƒì„±
        query_api = influx_client.query_api()
        
        # rangeì— ë”°ë¼ ì‹œì‘ ì‹œê°„ê³¼ ìœˆë„ìš° ê°„ê²© ê³„ì‚°
        now = datetime.utcnow()
        if range_param == '1h':
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        elif range_param == '6h':
            start_time = now - timedelta(hours=6)
            window_interval = '1m'
        elif range_param == '24h':
            start_time = now - timedelta(hours=24)
            window_interval = '5m'
        elif range_param == '7d':
            start_time = now - timedelta(days=7)
            window_interval = '30m'
        else:
            # ê¸°ë³¸ê°’: 1ì‹œê°„
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        
        start_time_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        # Flux ì¿¼ë¦¬ ì‘ì„± (createEmpty: trueë¡œ ì„¤ì •í•˜ì—¬ ë¹ˆ ì‹œê°„ëŒ€ë„ í¬í•¨)
        query = f'''
        from(bucket: "{VIBRATION_INFLUXDB_BUCKET}")
          |> range(start: {start_time_str})
          |> filter(fn: (r) => r["_measurement"] == "vibration")
          |> filter(fn: (r) => r["_field"] == "v_rms" or r["_field"] == "a_peak" or r["_field"] == "a_rms" or r["_field"] == "crest" or r["_field"] == "temperature")
          |> aggregateWindow(every: {window_interval}, fn: mean, createEmpty: true)
          |> yield(name: "mean")
        '''
        
        try:
            result = query_api.query(org=INFLUXDB_ORG, query=query)
        except Exception as bucket_error:
            # vibration_data ë²„í‚·ì´ ì—†ìœ¼ë©´ temperature_data ë²„í‚·ì—ì„œ ì¡°íšŒ
            print(f"âš ï¸ Failed to query {VIBRATION_INFLUXDB_BUCKET} bucket: {bucket_error}")
            print(f"âš ï¸ Trying to query {INFLUXDB_BUCKET} bucket as fallback...")
            query = f'''
            from(bucket: "{INFLUXDB_BUCKET}")
              |> range(start: {start_time_str})
              |> filter(fn: (r) => r["_measurement"] == "vibration")
              |> filter(fn: (r) => r["_field"] == "v_rms" or r["_field"] == "a_peak" or r["_field"] == "a_rms" or r["_field"] == "crest" or r["_field"] == "temperature")
              |> aggregateWindow(every: {window_interval}, fn: mean, createEmpty: true)
              |> yield(name: "mean")
            '''
            result = query_api.query(org=INFLUXDB_ORG, query=query)
        
        # ë°ì´í„° êµ¬ì¡°í™”
        timestamps = []
        v_rms_values = []
        a_peak_values = []
        a_rms_values = []
        crest_values = []
        temperature_values = []
        
        # ê° í•„ë“œë³„ë¡œ ë°ì´í„° ìˆ˜ì§‘
        for table in result:
            for record in table.records:
                timestamp_ms = int(record.get_time().timestamp() * 1000)
                field = record.get_field()
                value = record.get_value()
                
                if timestamp_ms not in timestamps:
                    timestamps.append(timestamp_ms)
                    v_rms_values.append(None)
                    a_peak_values.append(None)
                    a_rms_values.append(None)
                    crest_values.append(None)
                    temperature_values.append(None)
                
                idx = timestamps.index(timestamp_ms)
                
                if field == 'v_rms':
                    v_rms_values[idx] = value
                elif field == 'a_peak':
                    a_peak_values[idx] = value
                elif field == 'a_rms':
                    a_rms_values[idx] = value
                elif field == 'crest':
                    crest_values[idx] = value
                elif field == 'temperature':
                    temperature_values[idx] = value
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ì™€ ê°’ë“¤ì„ ì •ë ¬
        sorted_data = sorted(zip(timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values))
        if sorted_data:
            timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values = zip(*sorted_data)
        else:
            timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values = [], [], [], [], [], []
        
        return jsonify({
            'timestamps': list(timestamps),
            'v_rms': list(v_rms_values),
            'a_peak': list(a_peak_values),
            'a_rms': list(a_rms_values),
            'crest': list(crest_values),
            'temperature': list(temperature_values)
        })
    except Exception as e:
        print(f"âŒ Error getting vibration history: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/mqtt/vibration', methods=['GET'])
def stream_vibration():
    """Server-Sent Eventsë¥¼ í†µí•´ ì‹¤ì‹œê°„ ì§„ë™ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°"""
    def generate():
        try:
            while True:
                try:
                    # íì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 1ì´ˆ)
                    try:
                        data = vibration_queue.get(timeout=1)
                        yield f"data: {json.dumps(data)}\n\n"
                    except queue.Empty:
                        # í•˜íŠ¸ë¹„íŠ¸ ì „ì†¡ (ì—°ê²° ìœ ì§€)
                        yield f"data: {json.dumps({'heartbeat': True})}\n\n"
                except GeneratorExit:
                    print("SSE vibration connection closed by client")
                    break
                except Exception as e:
                    print(f"Error in vibration stream: {e}")
                    import traceback
                    traceback.print_exc()
                    break
        except Exception as e:
            print(f"Fatal error in vibration generate: {e}")
            import traceback
            traceback.print_exc()
    
    response = Response(stream_with_context(generate()), mimetype='text/event-stream')
    response.headers['Cache-Control'] = 'no-cache'
    response.headers['X-Accel-Buffering'] = 'no'
    return response

@app.route('/api/export/temperature/csv', methods=['GET'])
def export_temperature_csv():
    """ì˜¨ë„ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° (KST ì‹œê°„ ë²”ìœ„ ì§€ì •)"""
    if not query_api:
        return jsonify({'error': 'InfluxDB ì¿¼ë¦¬ APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500
    
    try:
        # 1. KST ì‹œê°„ íŒŒë¼ë¯¸í„° ë°›ê¸°
        start_time_kst_str = request.args.get('start_time_kst')  # "YYYY-MM-DD HH:MM:SS"
        end_time_kst_str = request.args.get('end_time_kst')
        
        if not start_time_kst_str or not end_time_kst_str:
            return jsonify({'error': 'ì‹œì‘ ì‹œê°„ê³¼ ì¢…ë£Œ ì‹œê°„ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        print(f"ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ ìš”ì²­: start_time_kst={start_time_kst_str}, end_time_kst={end_time_kst_str}")
        
        # 2. KST ë¬¸ìì—´ íŒŒì‹±
        try:
            start_kst = datetime.strptime(start_time_kst_str, '%Y-%m-%d %H:%M:%S')
            end_kst = datetime.strptime(end_time_kst_str, '%Y-%m-%d %H:%M:%S')
        except ValueError as e:
            return jsonify({'error': f'ì‹œê°„ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. í˜•ì‹: YYYY-MM-DD HH:MM:SS. ì˜¤ë¥˜: {e}'}), 400
        
        # 3. KST â†’ UTC ë³€í™˜ (KST = UTC + 9ì‹œê°„)
        start_utc = start_kst - timedelta(hours=9)
        end_utc = end_kst - timedelta(hours=9)
        
        print(f"ğŸ“… ë³€í™˜ëœ UTC ì‹œê°„: start={start_utc}, end={end_utc}")
        
        # 4. RFC3339 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (InfluxDB ì¿¼ë¦¬ìš©)
        start_rfc = start_utc.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        end_rfc = end_utc.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        
        print(f"ğŸ” InfluxDB ì¿¼ë¦¬ ë²”ìœ„: start={start_rfc}, end={end_rfc}")
        
        # 5. InfluxDB Flux ì¿¼ë¦¬ ì‹¤í–‰
        query = f'''
        from(bucket: "{INFLUXDB_BUCKET}")
          |> range(start: {start_rfc}, stop: {end_rfc})
          |> filter(fn: (r) => r["_measurement"] == "temperature")
          |> filter(fn: (r) => r["_field"] == "value")
          |> sort(columns: ["_time"])
        '''
        
        print(f"ğŸ“Š Flux ì¿¼ë¦¬:\n{query}")
        
        result = query_api.query(org=INFLUXDB_ORG, query=query)
        
        # 6. CSV ìƒì„±
        output = io.StringIO()
        writer = csv.writer(output)
        
        # UTF-8 BOM ì¶”ê°€ (Excel í˜¸í™˜ì„±)
        output.write('\ufeff')
        
        # í—¤ë” ì‘ì„±
        writer.writerow(['Time (UTC)', 'Time (KST)', 'Temperature (Â°C)'])
        
        # ë°ì´í„° í–‰ ì¶”ê°€
        row_count = 0
        for table in result:
            for record in table.records:
                time_utc = record.get_time()
                
                # timezone-awareì¸ ê²½ìš° naiveë¡œ ë³€í™˜
                if time_utc.tzinfo is not None:
                    time_utc_naive = time_utc.replace(tzinfo=None)
                else:
                    time_utc_naive = time_utc
                
                # Python ë ˆë²¨ì—ì„œ ì •í™•í•œ ë²”ìœ„ ì²´í¬
                if time_utc_naive < start_utc or time_utc_naive >= end_utc:
                    continue
                
                # UTC â†’ KST ë³€í™˜ (UTC+9)
                time_kst = time_utc_naive + timedelta(hours=9)
                value = record.get_value()
                
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ "--"ë¡œ í‘œì‹œ
                if value is None:
                    writer.writerow([
                        time_utc_naive.strftime('%Y-%m-%d %H:%M:%S'),
                        time_kst.strftime('%Y-%m-%d %H:%M:%S'),
                        '--'
                    ])
                else:
                    writer.writerow([
                        time_utc_naive.strftime('%Y-%m-%d %H:%M:%S'),
                        time_kst.strftime('%Y-%m-%d %H:%M:%S'),
                        f'{value:.2f}'
                    ])
                row_count += 1
        
        print(f"ğŸ“ˆ ì¡°íšŒëœ ë ˆì½”ë“œ ìˆ˜: {row_count}")
        
        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
        if row_count == 0:
            return jsonify({'error': 'ì„ íƒí•œ ì‹œê°„ ë²”ìœ„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # íŒŒì¼ëª… ìƒì„±
        filename_start = start_time_kst_str.replace('-', '').replace(':', '').replace(' ', '_')
        filename_end = end_time_kst_str.replace('-', '').replace(':', '').replace(' ', '_')
        filename = f'temperature_{filename_start}_{filename_end}.csv'
        
        # UTF-8 BOM í¬í•¨í•˜ì—¬ ì¸ì½”ë”©
        csv_content = output.getvalue()
        # ì´ë¯¸ output.write('\ufeff')ë¡œ BOMì„ ì¶”ê°€í–ˆìœ¼ë¯€ë¡œ utf-8ë¡œ ì¸ì½”ë”©
        csv_bytes = csv_content.encode('utf-8')
        
        # HTTP ì‘ë‹µ ìƒì„±
        response = make_response(csv_bytes)
        response.headers['Content-Type'] = 'text/csv; charset=utf-8'
        response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'
        response.headers['Content-Length'] = len(csv_bytes)
        
        print(f"âœ… CSV ìƒì„± ì™„ë£Œ: {row_count}ê°œ í–‰, íŒŒì¼ëª…: {filename}")
        
        return response
        
    except ValueError as e:
        return jsonify({'error': f'ì‹œê°„ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. í˜•ì‹: YYYY-MM-DD HH:MM:SS. ì˜¤ë¥˜: {e}'}), 400
    except Exception as e:
        print(f"âŒ CSV ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/export/vibration/csv', methods=['GET'])
def export_vibration_csv():
    """ì§„ë™ì„¼ì„œ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° (KST ì‹œê°„ ë²”ìœ„ ì§€ì •)"""
    if not query_api:
        return jsonify({'error': 'InfluxDB ì¿¼ë¦¬ APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500
    
    try:
        # 1. KST ì‹œê°„ íŒŒë¼ë¯¸í„° ë°›ê¸°
        start_time_kst_str = request.args.get('start_time_kst')  # "YYYY-MM-DD HH:MM:SS"
        end_time_kst_str = request.args.get('end_time_kst')
        
        if not start_time_kst_str or not end_time_kst_str:
            return jsonify({'error': 'ì‹œì‘ ì‹œê°„ê³¼ ì¢…ë£Œ ì‹œê°„ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        print(f"ğŸ“¥ ì§„ë™ì„¼ì„œ CSV ë‹¤ìš´ë¡œë“œ ìš”ì²­: start_time_kst={start_time_kst_str}, end_time_kst={end_time_kst_str}")
        
        # 2. KST ë¬¸ìì—´ íŒŒì‹±
        try:
            start_kst = datetime.strptime(start_time_kst_str, '%Y-%m-%d %H:%M:%S')
            end_kst = datetime.strptime(end_time_kst_str, '%Y-%m-%d %H:%M:%S')
        except ValueError as e:
            return jsonify({'error': f'ì‹œê°„ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. í˜•ì‹: YYYY-MM-DD HH:MM:SS. ì˜¤ë¥˜: {e}'}), 400
        
        # 3. KST â†’ UTC ë³€í™˜ (KST = UTC + 9ì‹œê°„)
        start_utc = start_kst - timedelta(hours=9)
        end_utc = end_kst - timedelta(hours=9)
        
        print(f"ğŸ“… ë³€í™˜ëœ UTC ì‹œê°„: start={start_utc}, end={end_utc}")
        
        # 4. RFC3339 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (InfluxDB ì¿¼ë¦¬ìš©)
        start_rfc = start_utc.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        end_rfc = end_utc.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        
        print(f"ğŸ” InfluxDB ì¿¼ë¦¬ ë²”ìœ„: start={start_rfc}, end={end_rfc}")
        
        # 5. InfluxDB Flux ì¿¼ë¦¬ ì‹¤í–‰ (ëª¨ë“  ì§„ë™ í•„ë“œ ì¡°íšŒ)
        query = f'''
        from(bucket: "{VIBRATION_INFLUXDB_BUCKET}")
          |> range(start: {start_rfc}, stop: {end_rfc})
          |> filter(fn: (r) => r["_measurement"] == "vibration")
          |> filter(fn: (r) => r["_field"] == "v_rms" or r["_field"] == "a_peak" or r["_field"] == "a_rms" or r["_field"] == "crest")
          |> sort(columns: ["_time"])
        '''
        
        print(f"ğŸ“Š Flux ì¿¼ë¦¬:\n{query}")
        
        try:
            result = query_api.query(org=INFLUXDB_ORG, query=query)
        except Exception as bucket_error:
            # vibration_data ë²„í‚·ì´ ì—†ìœ¼ë©´ temperature_data ë²„í‚·ì—ì„œ ì¡°íšŒ
            print(f"âš ï¸ Failed to query {VIBRATION_INFLUXDB_BUCKET} bucket: {bucket_error}")
            print(f"âš ï¸ Trying to query {INFLUXDB_BUCKET} bucket as fallback...")
            query = f'''
            from(bucket: "{INFLUXDB_BUCKET}")
              |> range(start: {start_rfc}, stop: {end_rfc})
              |> filter(fn: (r) => r["_measurement"] == "vibration")
              |> filter(fn: (r) => r["_field"] == "v_rms" or r["_field"] == "a_peak" or r["_field"] == "a_rms" or r["_field"] == "crest")
              |> sort(columns: ["_time"])
            '''
            result = query_api.query(org=INFLUXDB_ORG, query=query)
        
        # 6. ë°ì´í„°ë¥¼ ì‹œê°„ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ CSV ìƒì„±
        # ì‹œê°„ë³„ë¡œ ëª¨ë“  í•„ë“œë¥¼ í•˜ë‚˜ì˜ í–‰ì— ëª¨ìŒ
        data_by_time = {}
        
        for table in result:
            for record in table.records:
                time_utc = record.get_time()
                
                # timezone-awareì¸ ê²½ìš° naiveë¡œ ë³€í™˜
                if time_utc.tzinfo is not None:
                    time_utc_naive = time_utc.replace(tzinfo=None)
                else:
                    time_utc_naive = time_utc
                
                # Python ë ˆë²¨ì—ì„œ ì •í™•í•œ ë²”ìœ„ ì²´í¬
                if time_utc_naive < start_utc or time_utc_naive >= end_utc:
                    continue
                
                # ì‹œê°„ì„ í‚¤ë¡œ ì‚¬ìš©
                time_key = time_utc_naive.strftime('%Y-%m-%d %H:%M:%S')
                
                if time_key not in data_by_time:
                    # UTC â†’ KST ë³€í™˜ (UTC+9)
                    time_kst = time_utc_naive + timedelta(hours=9)
                    data_by_time[time_key] = {
                        'time_utc': time_utc_naive,
                        'time_kst': time_kst,
                        'v_rms': None,
                        'a_peak': None,
                        'a_rms': None,
                        'crest': None
                    }
                
                # í•„ë“œ ê°’ ì €ì¥
                field = record.get_field()
                value = record.get_value()
                if field in data_by_time[time_key]:
                    data_by_time[time_key][field] = value
        
        # 7. CSV ìƒì„±
        output = io.StringIO()
        writer = csv.writer(output)
        
        # UTF-8 BOM ì¶”ê°€ (Excel í˜¸í™˜ì„±)
        output.write('\ufeff')
        
        # í—¤ë” ì‘ì„±
        writer.writerow(['Time (UTC)', 'Time (KST)', 'v-RMS (mm/s)', 'a-Peak (m/sÂ²)', 'a-RMS (m/sÂ²)', 'Crest'])
        
        # ë°ì´í„° í–‰ ì¶”ê°€ (ì‹œê°„ìˆœ ì •ë ¬)
        row_count = 0
        for time_key in sorted(data_by_time.keys()):
            row_data = data_by_time[time_key]
            time_utc_str = row_data['time_utc'].strftime('%Y-%m-%d %H:%M:%S')
            time_kst_str = row_data['time_kst'].strftime('%Y-%m-%d %H:%M:%S')
            
            # ê°’ í¬ë§·íŒ… (Noneì´ë©´ "--"ë¡œ í‘œì‹œ)
            v_rms = '--' if row_data['v_rms'] is None else f"{row_data['v_rms']:.4f}"
            a_peak = '--' if row_data['a_peak'] is None else f"{row_data['a_peak']:.2f}"
            a_rms = '--' if row_data['a_rms'] is None else f"{row_data['a_rms']:.2f}"
            crest = '--' if row_data['crest'] is None else f"{row_data['crest']:.2f}"
            
            writer.writerow([time_utc_str, time_kst_str, v_rms, a_peak, a_rms, crest])
            row_count += 1
        
        print(f"ğŸ“ˆ ì¡°íšŒëœ ë ˆì½”ë“œ ìˆ˜: {row_count}")
        
        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
        if row_count == 0:
            return jsonify({'error': 'ì„ íƒí•œ ì‹œê°„ ë²”ìœ„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # íŒŒì¼ëª… ìƒì„±
        filename_start = start_time_kst_str.replace('-', '').replace(':', '').replace(' ', '_')
        filename_end = end_time_kst_str.replace('-', '').replace(':', '').replace(' ', '_')
        filename = f'vibration_{filename_start}_{filename_end}.csv'
        
        # UTF-8 BOM í¬í•¨í•˜ì—¬ ì¸ì½”ë”©
        csv_content = output.getvalue()
        csv_bytes = csv_content.encode('utf-8')
        
        # HTTP ì‘ë‹µ ìƒì„±
        response = make_response(csv_bytes)
        response.headers['Content-Type'] = 'text/csv; charset=utf-8'
        response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'
        response.headers['Content-Length'] = len(csv_bytes)
        
        print(f"âœ… ì§„ë™ì„¼ì„œ CSV ìƒì„± ì™„ë£Œ: {row_count}ê°œ í–‰, íŒŒì¼ëª…: {filename}")
        
        return response
        
    except ValueError as e:
        return jsonify({'error': f'ì‹œê°„ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. í˜•ì‹: YYYY-MM-DD HH:MM:SS. ì˜¤ë¥˜: {e}'}), 400
    except Exception as e:
        print(f"âŒ ì§„ë™ì„¼ì„œ CSV ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

# AI ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/ai/augmented/temperature', methods=['GET'])
def get_augmented_temperature():
    """ì¦ê°•ëœ ì˜¨ë„ ë°ì´í„° ì¡°íšŒ"""
    try:
        if influx_client is None:
            return jsonify({'error': 'InfluxDB not connected'}), 500
        
        range_param = request.args.get('range', '1h')
        query_api = influx_client.query_api()
        
        now = datetime.utcnow()
        if range_param == '1h':
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        elif range_param == '6h':
            start_time = now - timedelta(hours=6)
            window_interval = '1m'
        elif range_param == '24h':
            start_time = now - timedelta(hours=24)
            window_interval = '5m'
        elif range_param == '7d':
            start_time = now - timedelta(days=7)
            window_interval = '30m'
        else:
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        
        start_time_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        query = f'''
        from(bucket: "temperature_augmented")
          |> range(start: {start_time_str})
          |> filter(fn: (r) => r["_measurement"] == "temperature")
          |> filter(fn: (r) => r["_field"] == "value")
          |> aggregateWindow(every: {window_interval}, fn: mean, createEmpty: true)
          |> yield(name: "mean")
        '''
        
        result = query_api.query(org=INFLUXDB_ORG, query=query)
        
        timestamps = []
        values = []
        
        for table in result:
            for record in table.records:
                timestamp = record.get_time().timestamp() * 1000
                value = record.get_value()
                timestamps.append(timestamp)
                values.append(value if value is not None else None)
        
        if timestamps and values:
            sorted_data = sorted(zip(timestamps, values))
            timestamps, values = zip(*sorted_data)
            timestamps = list(timestamps)
            values = list(values)
        
        return jsonify({
            'timestamps': timestamps,
            'values': values,
            'count': len(values)
        })
        
    except Exception as e:
        print(f"âŒ Error querying augmented temperature: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/ai/augmented/vibration', methods=['GET'])
def get_augmented_vibration():
    """ì¦ê°•ëœ ì§„ë™ ë°ì´í„° ì¡°íšŒ"""
    try:
        if influx_client is None:
            return jsonify({'error': 'InfluxDB not connected'}), 500
        
        range_param = request.args.get('range', '1h')
        query_api = influx_client.query_api()
        
        now = datetime.utcnow()
        if range_param == '1h':
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        elif range_param == '6h':
            start_time = now - timedelta(hours=6)
            window_interval = '1m'
        elif range_param == '24h':
            start_time = now - timedelta(hours=24)
            window_interval = '5m'
        elif range_param == '7d':
            start_time = now - timedelta(days=7)
            window_interval = '30m'
        else:
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        
        start_time_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        query = f'''
        from(bucket: "vibration_augmented")
          |> range(start: {start_time_str})
          |> filter(fn: (r) => r["_measurement"] == "vibration")
          |> filter(fn: (r) => r["_field"] == "v_rms" or r["_field"] == "a_peak" or r["_field"] == "a_rms" or r["_field"] == "crest" or r["_field"] == "temperature")
          |> aggregateWindow(every: {window_interval}, fn: mean, createEmpty: true)
          |> yield(name: "mean")
        '''
        
        result = query_api.query(org=INFLUXDB_ORG, query=query)
        
        timestamps = []
        v_rms_values = []
        a_peak_values = []
        a_rms_values = []
        crest_values = []
        temperature_values = []
        
        for table in result:
            for record in table.records:
                timestamp_ms = int(record.get_time().timestamp() * 1000)
                field = record.get_field()
                value = record.get_value()
                
                if timestamp_ms not in timestamps:
                    timestamps.append(timestamp_ms)
                    v_rms_values.append(None)
                    a_peak_values.append(None)
                    a_rms_values.append(None)
                    crest_values.append(None)
                    temperature_values.append(None)
                
                idx = timestamps.index(timestamp_ms)
                
                if field == 'v_rms':
                    v_rms_values[idx] = value
                elif field == 'a_peak':
                    a_peak_values[idx] = value
                elif field == 'a_rms':
                    a_rms_values[idx] = value
                elif field == 'crest':
                    crest_values[idx] = value
                elif field == 'temperature':
                    temperature_values[idx] = value
        
        sorted_data = sorted(zip(timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values))
        if sorted_data:
            timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values = zip(*sorted_data)
        else:
            timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values = [], [], [], [], [], []
        
        return jsonify({
            'timestamps': list(timestamps),
            'v_rms': list(v_rms_values),
            'a_peak': list(a_peak_values),
            'a_rms': list(a_rms_values),
            'crest': list(crest_values),
            'temperature': list(temperature_values)
        })
    except Exception as e:
        print(f"âŒ Error querying augmented vibration: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/ai/original/temperature', methods=['GET'])
def get_original_temperature():
    """ì›ë³¸ ì˜¨ë„ ë°ì´í„° ì¡°íšŒ"""
    try:
        if influx_client is None:
            return jsonify({'error': 'InfluxDB not connected'}), 500
        
        range_param = request.args.get('range', '1h')
        query_api = influx_client.query_api()
        
        now = datetime.utcnow()
        if range_param == '1h':
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        elif range_param == '6h':
            start_time = now - timedelta(hours=6)
            window_interval = '1m'
        elif range_param == '24h':
            start_time = now - timedelta(hours=24)
            window_interval = '5m'
        elif range_param == '7d':
            start_time = now - timedelta(days=7)
            window_interval = '30m'
        else:
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        
        start_time_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        query = f'''
        from(bucket: "{INFLUXDB_BUCKET}")
          |> range(start: {start_time_str})
          |> filter(fn: (r) => r["_measurement"] == "temperature")
          |> filter(fn: (r) => r["_field"] == "value")
          |> aggregateWindow(every: {window_interval}, fn: mean, createEmpty: true)
          |> yield(name: "mean")
        '''
        
        result = query_api.query(org=INFLUXDB_ORG, query=query)
        
        timestamps = []
        values = []
        
        for table in result:
            for record in table.records:
                timestamp = record.get_time().timestamp() * 1000
                value = record.get_value()
                timestamps.append(timestamp)
                values.append(value if value is not None else None)
        
        if timestamps and values:
            sorted_data = sorted(zip(timestamps, values))
            timestamps, values = zip(*sorted_data)
            timestamps = list(timestamps)
            values = list(values)
        
        return jsonify({
            'timestamps': timestamps,
            'values': values,
            'count': len(values)
        })
        
    except Exception as e:
        print(f"âŒ Error querying original temperature: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/ai/original/vibration', methods=['GET'])
def get_original_vibration():
    """ì›ë³¸ ì§„ë™ ë°ì´í„° ì¡°íšŒ"""
    try:
        if influx_client is None:
            return jsonify({'error': 'InfluxDB not connected'}), 500
        
        range_param = request.args.get('range', '1h')
        query_api = influx_client.query_api()
        
        now = datetime.utcnow()
        if range_param == '1h':
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        elif range_param == '6h':
            start_time = now - timedelta(hours=6)
            window_interval = '1m'
        elif range_param == '24h':
            start_time = now - timedelta(hours=24)
            window_interval = '5m'
        elif range_param == '7d':
            start_time = now - timedelta(days=7)
            window_interval = '30m'
        else:
            start_time = now - timedelta(hours=1)
            window_interval = '10s'
        
        start_time_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        query = f'''
        from(bucket: "{VIBRATION_INFLUXDB_BUCKET}")
          |> range(start: {start_time_str})
          |> filter(fn: (r) => r["_measurement"] == "vibration")
          |> filter(fn: (r) => r["_field"] == "v_rms" or r["_field"] == "a_peak" or r["_field"] == "a_rms" or r["_field"] == "crest" or r["_field"] == "temperature")
          |> aggregateWindow(every: {window_interval}, fn: mean, createEmpty: true)
          |> yield(name: "mean")
        '''
        
        try:
            result = query_api.query(org=INFLUXDB_ORG, query=query)
        except Exception as bucket_error:
            # vibration_data ë²„í‚·ì´ ì—†ìœ¼ë©´ temperature_data ë²„í‚·ì—ì„œ ì¡°íšŒ
            print(f"âš ï¸ Failed to query {VIBRATION_INFLUXDB_BUCKET} bucket: {bucket_error}")
            print(f"âš ï¸ Trying to query {INFLUXDB_BUCKET} bucket as fallback...")
            try:
                query = f'''
                from(bucket: "{INFLUXDB_BUCKET}")
                  |> range(start: {start_time_str})
                  |> filter(fn: (r) => r["_measurement"] == "vibration")
                  |> filter(fn: (r) => r["_field"] == "v_rms" or r["_field"] == "a_peak" or r["_field"] == "a_rms" or r["_field"] == "crest" or r["_field"] == "temperature")
                  |> aggregateWindow(every: {window_interval}, fn: mean, createEmpty: true)
                  |> yield(name: "mean")
                '''
                result = query_api.query(org=INFLUXDB_ORG, query=query)
            except Exception as fallback_error:
                print(f"âŒ Failed to query fallback bucket: {fallback_error}")
                # ë¹ˆ ë°ì´í„° ë°˜í™˜
                return jsonify({
                    'timestamps': [],
                    'v_rms': [],
                    'a_peak': [],
                    'a_rms': [],
                    'crest': [],
                    'temperature': []
                })
        
        timestamps = []
        v_rms_values = []
        a_peak_values = []
        a_rms_values = []
        crest_values = []
        temperature_values = []
        
        for table in result:
            for record in table.records:
                timestamp_ms = int(record.get_time().timestamp() * 1000)
                field = record.get_field()
                value = record.get_value()
                
                if timestamp_ms not in timestamps:
                    timestamps.append(timestamp_ms)
                    v_rms_values.append(None)
                    a_peak_values.append(None)
                    a_rms_values.append(None)
                    crest_values.append(None)
                    temperature_values.append(None)
                
                idx = timestamps.index(timestamp_ms)
                
                if field == 'v_rms':
                    v_rms_values[idx] = value
                elif field == 'a_peak':
                    a_peak_values[idx] = value
                elif field == 'a_rms':
                    a_rms_values[idx] = value
                elif field == 'crest':
                    crest_values[idx] = value
                elif field == 'temperature':
                    temperature_values[idx] = value
        
        sorted_data = sorted(zip(timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values))
        if sorted_data:
            timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values = zip(*sorted_data)
        else:
            timestamps, v_rms_values, a_peak_values, a_rms_values, crest_values, temperature_values = [], [], [], [], [], []
        
        return jsonify({
            'timestamps': list(timestamps),
            'v_rms': list(v_rms_values),
            'a_peak': list(a_peak_values),
            'a_rms': list(a_rms_values),
            'crest': list(crest_values),
            'temperature': list(temperature_values)
        })
    except Exception as e:
        print(f"âŒ Error querying original vibration: {e}")
        import traceback
        traceback.print_exc()
        # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ë¹ˆ ë°ì´í„° ë°˜í™˜ (500 ì—ëŸ¬ ëŒ€ì‹ )
        return jsonify({
            'timestamps': [],
            'v_rms': [],
            'a_peak': [],
            'a_rms': [],
            'crest': [],
            'temperature': [],
            'error': str(e)
        })

@app.route('/api/ai/augment/temperature', methods=['POST'])
def run_temperature_augmentation():
    """ì˜¨ë„ ë°ì´í„° ì¦ê°• ì‹¤í–‰"""
    return run_data_augmentation('temperature')

@app.route('/api/ai/augment/vibration', methods=['POST'])
def run_vibration_augmentation():
    """ì§„ë™ ë°ì´í„° ì¦ê°• ì‹¤í–‰"""
    return run_data_augmentation('vibration')

@app.route('/api/ai/augment/stop', methods=['POST'])
def stop_augmentation():
    """ì¦ê°• í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ"""
    try:
        import os
        import subprocess
        import time
        import json
        
        killed_count = 0
        killed_pids = []
        
        # psutil ì‚¬ìš© ì‹œë„, ì—†ìœ¼ë©´ ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì‚¬ìš©
        try:
            import psutil
            use_psutil = True
        except ImportError:
            use_psutil = False
            print("âš ï¸ psutilì´ ì—†ì–´ ì‹œìŠ¤í…œ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        if use_psutil:
            # psutil ì‚¬ìš©
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = proc.info.get('cmdline', [])
                    if cmdline and 'data_augmentation.py' in ' '.join(cmdline):
                        pid = proc.info['pid']
                        print(f"ğŸ›‘ ì¦ê°• í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ: PID {pid}")
                        proc.terminate()
                        killed_count += 1
                        killed_pids.append(pid)
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    pass
        else:
            # ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì‚¬ìš© (Linux)
            try:
                # pgrepìœ¼ë¡œ data_augmentation.pyë¥¼ ì‹¤í–‰í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ ì°¾ê¸°
                result = subprocess.run(
                    ['pgrep', '-f', 'data_augmentation.py'],
                    capture_output=True,
                    text=True,
                    timeout=5
                )
                
                if result.returncode == 0:
                    pids = result.stdout.strip().split('\n')
                    for pid_str in pids:
                        if pid_str.strip():
                            try:
                                pid = int(pid_str.strip())
                                print(f"ğŸ›‘ ì¦ê°• í”„ë¡œì„¸ìŠ¤ ë°œê²¬: PID {pid}")
                                killed_pids.append(pid)
                                killed_count += 1
                            except ValueError:
                                pass
            except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError) as e:
                print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                # ps ëª…ë ¹ì–´ë¡œ ì‹œë„
                try:
                    result = subprocess.run(
                        ['ps', 'aux'],
                        capture_output=True,
                        text=True,
                        timeout=5
                    )
                    if result.returncode == 0:
                        for line in result.stdout.split('\n'):
                            if 'data_augmentation.py' in line:
                                parts = line.split()
                                if len(parts) > 1:
                                    try:
                                        pid = int(parts[1])
                                        print(f"ğŸ›‘ ì¦ê°• í”„ë¡œì„¸ìŠ¤ ë°œê²¬: PID {pid}")
                                        killed_pids.append(pid)
                                        killed_count += 1
                                    except (ValueError, IndexError):
                                        pass
                except Exception as e2:
                    print(f"âš ï¸ ps ëª…ë ¹ì–´ë„ ì‹¤íŒ¨: {e2}")
        
        if killed_count > 0:
            # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
            for pid in killed_pids:
                try:
                    if use_psutil:
                        proc = psutil.Process(pid)
                        proc.terminate()
                    else:
                        # SIGTERM ì‹ í˜¸ ì „ì†¡
                        subprocess.run(['kill', '-TERM', str(pid)], timeout=2)
                except Exception as e:
                    print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {pid} ì¢…ë£Œ ì‹¤íŒ¨: {e}")
            
            # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ëŒ€ê¸°
            time.sleep(1)
            
            # ê°•ì œ ì¢…ë£Œê°€ í•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ í™•ì¸
            for pid in killed_pids:
                try:
                    if use_psutil:
                        proc = psutil.Process(pid)
                        if proc.is_running():
                            print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {pid}ê°€ ì¢…ë£Œë˜ì§€ ì•Šì•„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            proc.kill()
                    else:
                        # í”„ë¡œì„¸ìŠ¤ê°€ ì—¬ì „íˆ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ê³  ê°•ì œ ì¢…ë£Œ
                        try:
                            subprocess.run(['kill', '-0', str(pid)], timeout=1, check=True)
                            # í”„ë¡œì„¸ìŠ¤ê°€ ì‚´ì•„ìˆìœ¼ë©´ ê°•ì œ ì¢…ë£Œ
                            print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {pid}ê°€ ì¢…ë£Œë˜ì§€ ì•Šì•„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            subprocess.run(['kill', '-KILL', str(pid)], timeout=2)
                        except subprocess.CalledProcessError:
                            # í”„ë¡œì„¸ìŠ¤ê°€ ì´ë¯¸ ì¢…ë£Œë¨
                            pass
                except Exception as e:
                    print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {pid} ê°•ì œ ì¢…ë£Œ ì‹¤íŒ¨: {e}")
            
            # ì§„í–‰ë¥  íŒŒì¼ ì´ˆê¸°í™”
            backend_dir = os.path.dirname(os.path.abspath(__file__))
            simpac_dir = os.path.join(backend_dir, '..', '..')
            ai_ml_path = os.path.join(simpac_dir, 'ai_ml')
            progress_file = os.path.join(ai_ml_path, 'data', 'augment_progress.json')
            progress_file = os.path.abspath(progress_file)
            try:
                os.makedirs(os.path.dirname(progress_file), exist_ok=True)
                with open(progress_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'stage': 'stopped',
                        'progress': 0,
                        'message': 'ì¦ê°•ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.'
                    }, f)
            except Exception as e:
                print(f"âš ï¸ ì§„í–‰ë¥  íŒŒì¼ ì´ˆê¸°í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
            
            print(f"âœ… {killed_count}ê°œì˜ ì¦ê°• í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨")
            return jsonify({
                'status': 'stopped',
                'message': f'{killed_count}ê°œì˜ ì¦ê°• í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'killed_count': killed_count
            })
        else:
            return jsonify({
                'status': 'not_found',
                'message': 'ì‹¤í–‰ ì¤‘ì¸ ì¦ê°• í”„ë¡œì„¸ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.'
            })
            
    except Exception as e:
        print(f"âŒ ì¦ê°• í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

def run_data_augmentation(data_type='both'):
    """ë°ì´í„° ì¦ê°• ì‹¤í–‰ (ì˜¨ë„/ì§„ë™ ê°ê° ë˜ëŠ” ë‘˜ ë‹¤)"""
    try:
        import sys
        import os
        import subprocess
        
        # ai_ml ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ (SIMPAC í´ë” ê¸°ì¤€)
        backend_dir = os.path.dirname(os.path.abspath(__file__))
        simpac_dir = os.path.join(backend_dir, '..', '..')
        ai_ml_path = os.path.join(simpac_dir, 'ai_ml')
        script_path = os.path.join(ai_ml_path, 'scripts', 'data_augmentation.py')
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        script_path = os.path.abspath(script_path)
        ai_ml_path = os.path.abspath(ai_ml_path)
        
        if not os.path.exists(script_path):
            print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì—†ìŒ: {script_path}")
            print(f"   ai_ml_path: {ai_ml_path}")
            print(f"   ì¡´ì¬ ì—¬ë¶€: {os.path.exists(ai_ml_path)}")
            return jsonify({'error': f'ë°ì´í„° ì¦ê°• ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {script_path}'}), 404
        
        print(f"âœ… ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ í™•ì¸: {script_path}")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        def run_augmentation():
            try:
                print(f"ğŸš€ ë°ì´í„° ì¦ê°• ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œì‘: {script_path}")
                print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {ai_ml_path}")
                
                # Python ê²½ë¡œ ì°¾ê¸° (ai_ml venv ìš°ì„ , ì—†ìœ¼ë©´ ë°±ì—”ë“œ venv, ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹œìŠ¤í…œ python3)
                python_path = 'python3'
                ai_ml_venv = os.path.join(ai_ml_path, 'venv', 'bin', 'python3')
                backend_venv = os.path.join(os.path.dirname(__file__), 'venv', 'bin', 'python3')
                
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                ai_ml_venv = os.path.abspath(ai_ml_venv)
                backend_venv = os.path.abspath(backend_venv)
                
                if os.path.exists(ai_ml_venv):
                    python_path = ai_ml_venv
                    print(f"âœ… ai_ml venv Python ì‚¬ìš©: {python_path}")
                    # venv ì¡´ì¬ í™•ì¸
                    if not os.path.exists(python_path):
                        print(f"âŒ Python ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {python_path}")
                        raise FileNotFoundError(f"Python ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {python_path}")
                elif os.path.exists(backend_venv):
                    python_path = backend_venv
                    print(f"âœ… ë°±ì—”ë“œ venv Python ì‚¬ìš©: {python_path}")
                else:
                    print(f"âš ï¸ ì‹œìŠ¤í…œ Python ì‚¬ìš©: {python_path}")
                    # ì‹œìŠ¤í…œ Pythonë„ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ ì‹œë„
                    import shutil
                    system_python = shutil.which('python3')
                    if system_python:
                        python_path = system_python
                        print(f"   ì‹œìŠ¤í…œ Python ê²½ë¡œ: {python_path}")
                
                # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                env = os.environ.copy()
                # venvê°€ ìˆìœ¼ë©´ PATHì— ì¶”ê°€í•˜ê³  PYTHONPATH ì„¤ì •
                if os.path.exists(ai_ml_venv):
                    venv_bin = os.path.dirname(ai_ml_venv)
                    venv_lib = os.path.join(os.path.dirname(venv_bin), 'lib')
                    # Python ë²„ì „ì— ë§ëŠ” site-packages ê²½ë¡œ ì°¾ê¸°
                    python_version = f"python{os.sys.version_info.major}.{os.sys.version_info.minor}"
                    site_packages = os.path.join(venv_lib, python_version, 'site-packages')
                    env['PATH'] = f"{venv_bin}:{env.get('PATH', '')}"
                    if os.path.exists(site_packages):
                        env['PYTHONPATH'] = f"{site_packages}:{env.get('PYTHONPATH', '')}"
                    print(f"âœ… í™˜ê²½ ë³€ìˆ˜ ì„¤ì •: PATH={venv_bin}, PYTHONPATH={site_packages if os.path.exists(site_packages) else 'N/A'}")
                elif os.path.exists(backend_venv):
                    venv_bin = os.path.dirname(backend_venv)
                    env['PATH'] = f"{venv_bin}:{env.get('PATH', '')}"
                
                # Python ê²½ë¡œ í™•ì¸ ë° í…ŒìŠ¤íŠ¸
                try:
                    import subprocess as sp
                    # ì‹¤ì œ ì‚¬ìš©í•  Python ê²½ë¡œë¡œ í…ŒìŠ¤íŠ¸
                    test_cmd = [python_path, '-c', 'import sys; print(sys.executable); import numpy; print("numpy OK")']
                    test_result = sp.run(test_cmd, 
                                       capture_output=True, text=True, timeout=10, env=env, cwd=ai_ml_path)
                    print(f"ğŸ” Python í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
                    print(f"   ëª…ë ¹: {' '.join(test_cmd)}")
                    print(f"   ë°˜í™˜ ì½”ë“œ: {test_result.returncode}")
                    print(f"   stdout: {test_result.stdout}")
                    if test_result.returncode != 0:
                        print(f"   âš ï¸ stderr: {test_result.stderr}")
                    else:
                        print(f"âœ… Python ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {python_path}")
                except Exception as e:
                    print(f"âš ï¸ Python ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                
                # ë¹„ë™ê¸° ì‹¤í–‰ (Popen ì‚¬ìš©)
                print(f"ğŸš€ í”„ë¡œì„¸ìŠ¤ ì‹œì‘: {python_path} {script_path}")
                print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {ai_ml_path}")
                print(f"ğŸ”§ í™˜ê²½ ë³€ìˆ˜:")
                print(f"   PATH: {env.get('PATH', 'N/A')[:100]}...")
                print(f"   PYTHONPATH: {env.get('PYTHONPATH', 'N/A')}")
                
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                python_path_abs = os.path.abspath(python_path) if not os.path.isabs(python_path) else python_path
                script_path_abs = os.path.abspath(script_path)
                
                # ë°ì´í„° íƒ€ì…ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ì „ë‹¬
                env['AUGMENT_TYPE'] = data_type
                
                process = subprocess.Popen(
                    [python_path_abs, script_path_abs],
                    cwd=ai_ml_path,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    env=env,
                    bufsize=1  # ë¼ì¸ ë²„í¼ë§
                )
                
                print(f"âœ… í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¨ (PID: {process.pid})")
                print(f"   Python: {python_path_abs}")
                print(f"   Script: {script_path_abs}")
                
                # ë¹„ë™ê¸°ë¡œ ì¶œë ¥ ì½ê¸°
                def read_output():
                    try:
                        for line in process.stdout:
                            line_str = line.strip()
                            if line_str:
                                print(f"[ì¦ê°•] {line_str}")
                    except Exception as e:
                        print(f"âš ï¸ ì¶œë ¥ ì½ê¸° ì˜¤ë¥˜: {e}")
                        import traceback
                        traceback.print_exc()
                
                def read_error():
                    try:
                        error_lines = []
                        for line in process.stderr:
                            line_str = line.strip()
                            if line_str:
                                error_lines.append(line_str)
                                print(f"[ì¦ê°•-ì—ëŸ¬] {line_str}")
                        
                        # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ í›„ ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ìƒì„¸ ì¶œë ¥
                        if error_lines:
                            print(f"âŒ ì´ {len(error_lines)}ê°œì˜ ì—ëŸ¬ ë¼ì¸ ë°œê²¬")
                    except Exception as e:
                        print(f"âš ï¸ ì—ëŸ¬ ì½ê¸° ì˜¤ë¥˜: {e}")
                        import traceback
                        traceback.print_exc()
                
                # ì¶œë ¥ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì½ê¸°
                import threading
                stdout_thread = threading.Thread(target=read_output, daemon=True)
                stderr_thread = threading.Thread(target=read_error, daemon=True)
                stdout_thread.start()
                stderr_thread.start()
                
                # í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ì „íˆ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰ (wait() ì œê±°)
                # ì§„í–‰ë¥ ì€ íŒŒì¼ë¡œ ì¶”ì í•˜ë¯€ë¡œ í”„ë¡œì„¸ìŠ¤ë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ
                print(f"âœ… í”„ë¡œì„¸ìŠ¤ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤ (PID: {process.pid})")
                print(f"ğŸ“Š ì§„í–‰ë¥ ì€ /api/ai/progress/augmentë¡œ í™•ì¸í•˜ì„¸ìš”")
                
                # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
                def wait_for_completion():
                    return_code = process.wait()
                    if return_code != 0:
                        print(f"âŒ ë°ì´í„° ì¦ê°• ì˜¤ë¥˜ (ì½”ë“œ: {return_code})")
                    else:
                        print(f"âœ… ë°ì´í„° ì¦ê°• ì™„ë£Œ")
                
                completion_thread = threading.Thread(target=wait_for_completion, daemon=True)
                completion_thread.start()
                    
            except FileNotFoundError as e:
                print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {e}")
                print(f"   ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ: {script_path}")
                print(f"   ì¡´ì¬ ì—¬ë¶€: {os.path.exists(script_path)}")
            except Exception as e:
                print(f"âŒ ë°ì´í„° ì¦ê°• ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        import threading
        thread = threading.Thread(target=run_augmentation, daemon=True)
        thread.start()
        
        data_type_name = {'temperature': 'ì˜¨ë„', 'vibration': 'ì§„ë™', 'both': 'ì˜¨ë„ ë° ì§„ë™'}.get(data_type, 'ë°ì´í„°')
        return jsonify({
            'status': 'started',
            'message': f'{data_type_name} ë°ì´í„° ì¦ê°•ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì™„ë£Œê¹Œì§€ ëª‡ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
            'data_type': data_type,
            'progress_file': os.path.join(ai_ml_path, 'data', 'augment_progress.json')
        })
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¦ê°• API ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/ai/train', methods=['POST'])
def train_model():
    """ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"""
    try:
        import sys
        import os
        import subprocess
        
        # ìš”ì²­ì—ì„œ ëª¨ë¸ íƒ€ì… ë° ë°ì´í„° ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: lstm, ì¦ê°• ë°ì´í„°)
        model_type = 'lstm'
        use_original_temp = False
        use_original_vib = False
        
        if request.is_json:
            data = request.get_json()
            model_type = data.get('model_type', 'lstm')
            use_original_temp = data.get('use_original_temp', False)
            use_original_vib = data.get('use_original_vib', False)
        
        # ìœ íš¨í•œ ëª¨ë¸ íƒ€ì… í™•ì¸
        valid_models = ['lstm', 'gru', 'transformer']
        if model_type not in valid_models:
            return jsonify({'error': f'ìœ íš¨í•˜ì§€ ì•Šì€ ëª¨ë¸ íƒ€ì…ì…ë‹ˆë‹¤. ê°€ëŠ¥í•œ ê°’: {", ".join(valid_models)}'}), 400
        
        # ai_ml ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ (SIMPAC í´ë” ê¸°ì¤€)
        backend_dir = os.path.dirname(os.path.abspath(__file__))
        simpac_dir = os.path.join(backend_dir, '..', '..')
        ai_ml_path = os.path.join(simpac_dir, 'ai_ml')
        script_path = os.path.join(ai_ml_path, 'scripts', 'train_model.py')
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        script_path = os.path.abspath(script_path)
        ai_ml_path = os.path.abspath(ai_ml_path)
        
        if not os.path.exists(script_path):
            return jsonify({'error': f'ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {script_path}'}), 404
        
        # ê¸°ì¡´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
        try:
            import psutil
            killed_count = 0
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = proc.info.get('cmdline', [])
                    if cmdline and 'train_model.py' in ' '.join(cmdline):
                        print(f"ğŸ›‘ ê¸°ì¡´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ: PID {proc.info['pid']}")
                        proc.terminate()
                        killed_count += 1
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            if killed_count > 0:
                print(f"âœ… {killed_count}ê°œì˜ ê¸°ì¡´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨")
                import time
                time.sleep(2)  # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ëŒ€ê¸°
        except ImportError:
            print("âš ï¸ psutilì´ ì—†ì–´ ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        
        # ì´ì „ ì§„í–‰ë¥  íŒŒì¼ ì´ˆê¸°í™” (ì—ëŸ¬ ìƒíƒœ ì œê±°)
        progress_file = os.path.join(ai_ml_path, 'data', 'train_progress.json')
        progress_file = os.path.abspath(progress_file)
        try:
            import json
            os.makedirs(os.path.dirname(progress_file), exist_ok=True)
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'stage': 'not_started',
                    'progress': 0,
                    'message': 'í•™ìŠµ ì‹œì‘ ì¤‘...'
                }, f)
        except Exception as e:
            print(f"âš ï¸ ì§„í–‰ë¥  íŒŒì¼ ì´ˆê¸°í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        def run_training():
            try:
                print(f"ğŸš€ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œì‘: {script_path}")
                print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {ai_ml_path}")
                
                # Python ê²½ë¡œ ì°¾ê¸° (ai_ml venv ìš°ì„ , ì—†ìœ¼ë©´ ë°±ì—”ë“œ venv, ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹œìŠ¤í…œ python3)
                python_path = 'python3'
                ai_ml_venv = os.path.join(ai_ml_path, 'venv', 'bin', 'python3')
                backend_venv = os.path.join(os.path.dirname(__file__), 'venv', 'bin', 'python3')
                
                if os.path.exists(ai_ml_venv):
                    python_path = ai_ml_venv
                    print(f"âœ… ai_ml venv Python ì‚¬ìš©: {python_path}")
                elif os.path.exists(backend_venv):
                    python_path = backend_venv
                    print(f"âœ… ë°±ì—”ë“œ venv Python ì‚¬ìš©: {python_path}")
                else:
                    print(f"âš ï¸ ì‹œìŠ¤í…œ Python ì‚¬ìš©: {python_path}")
                
                # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                env = os.environ.copy()
                # ëª¨ë¸ íƒ€ì… ë° ë°ì´í„° ì†ŒìŠ¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì „ë‹¬
                env['MODEL_TYPE'] = model_type
                env['USE_ORIGINAL_TEMP'] = '1' if use_original_temp else '0'
                env['USE_ORIGINAL_VIB'] = '1' if use_original_vib else '0'
                print(f"ğŸ“Œ ëª¨ë¸ íƒ€ì…: {model_type}")
                print(f"ğŸ“Œ ë°ì´í„° ì†ŒìŠ¤ - ì˜¨ë„: {'ì›ë³¸' if use_original_temp else 'ì¦ê°•'}, ì§„ë™: {'ì›ë³¸' if use_original_vib else 'ì¦ê°•'}")
                # venvê°€ ìˆìœ¼ë©´ PATHì— ì¶”ê°€í•˜ê³  PYTHONPATH ì„¤ì •
                if os.path.exists(ai_ml_venv):
                    venv_bin = os.path.dirname(ai_ml_venv)
                    venv_lib = os.path.join(os.path.dirname(venv_bin), 'lib')
                    # Python ë²„ì „ì— ë§ëŠ” site-packages ê²½ë¡œ ì°¾ê¸°
                    python_version = f"python{os.sys.version_info.major}.{os.sys.version_info.minor}"
                    site_packages = os.path.join(venv_lib, python_version, 'site-packages')
                    env['PATH'] = f"{venv_bin}:{env.get('PATH', '')}"
                    if os.path.exists(site_packages):
                        env['PYTHONPATH'] = f"{site_packages}:{env.get('PYTHONPATH', '')}"
                    print(f"âœ… í™˜ê²½ ë³€ìˆ˜ ì„¤ì •: PATH={venv_bin}, PYTHONPATH={site_packages if os.path.exists(site_packages) else 'N/A'}")
                elif os.path.exists(backend_venv):
                    venv_bin = os.path.dirname(backend_venv)
                    env['PATH'] = f"{venv_bin}:{env.get('PATH', '')}"
                
                # Python ê²½ë¡œ í™•ì¸ ë° í…ŒìŠ¤íŠ¸
                try:
                    import subprocess as sp
                    # ì‹¤ì œ ì‚¬ìš©í•  Python ê²½ë¡œë¡œ í…ŒìŠ¤íŠ¸
                    test_cmd = [python_path, '-c', 'import sys; print(sys.executable); import numpy; import torch; print("numpy, torch OK")']
                    test_result = sp.run(test_cmd, 
                                       capture_output=True, text=True, timeout=10, env=env, cwd=ai_ml_path)
                    print(f"ğŸ” Python í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
                    print(f"   ëª…ë ¹: {' '.join(test_cmd)}")
                    print(f"   ë°˜í™˜ ì½”ë“œ: {test_result.returncode}")
                    print(f"   stdout: {test_result.stdout}")
                    if test_result.returncode != 0:
                        print(f"   âš ï¸ stderr: {test_result.stderr}")
                    else:
                        print(f"âœ… Python ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {python_path}")
                except Exception as e:
                    print(f"âš ï¸ Python ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                
                # ë¹„ë™ê¸° ì‹¤í–‰ (Popen ì‚¬ìš©)
                print(f"ğŸš€ í”„ë¡œì„¸ìŠ¤ ì‹œì‘: {python_path} {script_path} (ëª¨ë¸ íƒ€ì…: {model_type})")
                process = subprocess.Popen(
                    [python_path, script_path],
                    cwd=ai_ml_path,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    env=env,
                    bufsize=1
                )
                
                print(f"âœ… í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¨ (PID: {process.pid})")
                
                # ë¹„ë™ê¸°ë¡œ ì¶œë ¥ ì½ê¸°
                def read_output():
                    try:
                        for line in process.stdout:
                            print(f"[í•™ìŠµ] {line.strip()}")
                    except Exception as e:
                        print(f"âš ï¸ ì¶œë ¥ ì½ê¸° ì˜¤ë¥˜: {e}")
                
                def read_error():
                    try:
                        for line in process.stderr:
                            print(f"[í•™ìŠµ-ì—ëŸ¬] {line.strip()}")
                    except Exception as e:
                        print(f"âš ï¸ ì—ëŸ¬ ì½ê¸° ì˜¤ë¥˜: {e}")
                
                # ì¶œë ¥ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì½ê¸°
                import threading
                stdout_thread = threading.Thread(target=read_output, daemon=True)
                stderr_thread = threading.Thread(target=read_error, daemon=True)
                stdout_thread.start()
                stderr_thread.start()
                
                # í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ì „íˆ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰ (wait() ì œê±°)
                print(f"âœ… í”„ë¡œì„¸ìŠ¤ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤ (PID: {process.pid})")
                print(f"ğŸ“Š ì§„í–‰ë¥ ì€ /api/ai/progress/trainìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”")
                
                # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
                def wait_for_completion():
                    return_code = process.wait()
                    if return_code != 0:
                        print(f"âŒ ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜ (ì½”ë“œ: {return_code})")
                    else:
                        print(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
                
                completion_thread = threading.Thread(target=wait_for_completion, daemon=True)
                completion_thread.start()
                    
            except Exception as e:
                print(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        import threading
        thread = threading.Thread(target=run_training, daemon=True)
        thread.start()
        
        data_source_info = []
        if use_original_temp:
            data_source_info.append('ì›ë³¸ ì˜¨ë„')
        else:
            data_source_info.append('ì¦ê°• ì˜¨ë„')
        if use_original_vib:
            data_source_info.append('ì›ë³¸ ì§„ë™')
        else:
            data_source_info.append('ì¦ê°• ì§„ë™')
        
        return jsonify({
            'status': 'started',
            'message': f'ëª¨ë¸ í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ ({model_type.upper()} ëª¨ë¸, {", ".join(data_source_info)}). ì™„ë£Œê¹Œì§€ ëª‡ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
            'model_type': model_type,
            'use_original_temp': use_original_temp,
            'use_original_vib': use_original_vib,
            'progress_file': os.path.join(ai_ml_path, 'data', 'train_progress.json')
        })
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í•™ìŠµ API ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/ai/train/stop', methods=['POST'])
def stop_training():
    """í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ"""
    try:
        import os
        import subprocess
        import time
        import json
        
        killed_count = 0
        killed_pids = []
        
        # psutil ì‚¬ìš© ì‹œë„, ì—†ìœ¼ë©´ ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì‚¬ìš©
        try:
            import psutil
            use_psutil = True
        except ImportError:
            use_psutil = False
            print("âš ï¸ psutilì´ ì—†ì–´ ì‹œìŠ¤í…œ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        if use_psutil:
            # psutil ì‚¬ìš©
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = proc.info.get('cmdline', [])
                    if cmdline and 'train_model.py' in ' '.join(cmdline):
                        pid = proc.info['pid']
                        print(f"ğŸ›‘ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ: PID {pid}")
                        proc.terminate()
                        killed_count += 1
                        killed_pids.append(pid)
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    pass
        else:
            # ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì‚¬ìš© (Linux)
            try:
                # pgrepìœ¼ë¡œ train_model.pyë¥¼ ì‹¤í–‰í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ ì°¾ê¸°
                result = subprocess.run(
                    ['pgrep', '-f', 'train_model.py'],
                    capture_output=True,
                    text=True,
                    timeout=5
                )
                
                if result.returncode == 0:
                    pids = result.stdout.strip().split('\n')
                    for pid_str in pids:
                        if pid_str.strip():
                            try:
                                pid = int(pid_str.strip())
                                print(f"ğŸ›‘ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ë°œê²¬: PID {pid}")
                                killed_pids.append(pid)
                                killed_count += 1
                            except ValueError:
                                pass
            except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError) as e:
                print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                # ps ëª…ë ¹ì–´ë¡œ ì‹œë„
                try:
                    result = subprocess.run(
                        ['ps', 'aux'],
                        capture_output=True,
                        text=True,
                        timeout=5
                    )
                    if result.returncode == 0:
                        for line in result.stdout.split('\n'):
                            if 'train_model.py' in line:
                                parts = line.split()
                                if len(parts) > 1:
                                    try:
                                        pid = int(parts[1])
                                        print(f"ğŸ›‘ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ë°œê²¬: PID {pid}")
                                        killed_pids.append(pid)
                                        killed_count += 1
                                    except (ValueError, IndexError):
                                        pass
                except Exception as e2:
                    print(f"âš ï¸ ps ëª…ë ¹ì–´ë„ ì‹¤íŒ¨: {e2}")
        
        if killed_count > 0:
            # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
            for pid in killed_pids:
                try:
                    if use_psutil:
                        proc = psutil.Process(pid)
                        proc.terminate()
                    else:
                        # SIGTERM ì‹ í˜¸ ì „ì†¡
                        subprocess.run(['kill', '-TERM', str(pid)], timeout=2)
                except Exception as e:
                    print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {pid} ì¢…ë£Œ ì‹¤íŒ¨: {e}")
            
            # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ëŒ€ê¸°
            time.sleep(1)
            
            # ê°•ì œ ì¢…ë£Œê°€ í•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ í™•ì¸
            for pid in killed_pids:
                try:
                    if use_psutil:
                        proc = psutil.Process(pid)
                        if proc.is_running():
                            print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {pid}ê°€ ì¢…ë£Œë˜ì§€ ì•Šì•„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            proc.kill()
                    else:
                        # í”„ë¡œì„¸ìŠ¤ê°€ ì—¬ì „íˆ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ê³  ê°•ì œ ì¢…ë£Œ
                        try:
                            subprocess.run(['kill', '-0', str(pid)], timeout=1, check=True)
                            # í”„ë¡œì„¸ìŠ¤ê°€ ì‚´ì•„ìˆìœ¼ë©´ ê°•ì œ ì¢…ë£Œ
                            print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {pid}ê°€ ì¢…ë£Œë˜ì§€ ì•Šì•„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            subprocess.run(['kill', '-KILL', str(pid)], timeout=2)
                        except subprocess.CalledProcessError:
                            # í”„ë¡œì„¸ìŠ¤ê°€ ì´ë¯¸ ì¢…ë£Œë¨
                            pass
                except Exception as e:
                    print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {pid} ê°•ì œ ì¢…ë£Œ ì‹¤íŒ¨: {e}")
            
            # ì§„í–‰ë¥  íŒŒì¼ ì´ˆê¸°í™”
            backend_dir = os.path.dirname(os.path.abspath(__file__))
            simpac_dir = os.path.join(backend_dir, '..', '..')
            ai_ml_path = os.path.join(simpac_dir, 'ai_ml')
            progress_file = os.path.join(ai_ml_path, 'data', 'train_progress.json')
            progress_file = os.path.abspath(progress_file)
            try:
                os.makedirs(os.path.dirname(progress_file), exist_ok=True)
                with open(progress_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'stage': 'stopped',
                        'progress': 0,
                        'message': 'í•™ìŠµì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.'
                    }, f)
            except Exception as e:
                print(f"âš ï¸ ì§„í–‰ë¥  íŒŒì¼ ì´ˆê¸°í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
            
            print(f"âœ… {killed_count}ê°œì˜ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨")
            return jsonify({
                'status': 'stopped',
                'message': f'{killed_count}ê°œì˜ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'killed_count': killed_count
            })
        else:
            return jsonify({
                'status': 'not_found',
                'message': 'ì‹¤í–‰ ì¤‘ì¸ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.'
            })
            
    except Exception as e:
        print(f"âŒ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/ai/predict', methods=['GET'])
def ai_predict():
    """AI ì˜ˆì¸¡ ìˆ˜í–‰"""
    try:
        import sys
        import os
        import json
        
        # í•™ìŠµ ì¤‘ì¸ì§€ í™•ì¸
        backend_dir = os.path.dirname(os.path.abspath(__file__))
        simpac_dir = os.path.join(backend_dir, '..', '..')
        ai_ml_path = os.path.join(simpac_dir, 'ai_ml')
        progress_file = os.path.join(ai_ml_path, 'data', 'train_progress.json')
        
        if os.path.exists(progress_file):
            try:
                with open(progress_file, 'r', encoding='utf-8') as f:
                    progress_data = json.load(f)
                    stage = progress_data.get('stage', '')
                    # í•™ìŠµ ì¤‘ì´ë©´ ì˜ˆì¸¡ ë¶ˆê°€
                    if stage in ['training', 'loading', 'preparing', 'saving']:
                        return jsonify({
                            'error': 'ëª¨ë¸ í•™ìŠµì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í•™ìŠµì´ ì™„ë£Œëœ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
                            'stage': stage,
                            'progress': progress_data.get('progress', 0),
                            'message': progress_data.get('message', '')
                        }), 503  # Service Unavailable
            except Exception as e:
                print(f"âš ï¸ ì§„í–‰ë¥  íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        
        # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸ (PyTorchë§Œ ì‚¬ìš©)
        model_dir = os.path.join(ai_ml_path, 'models')
        model_path = os.path.join(model_dir, 'model.pth')  # PyTorch ëª¨ë¸
        
        if not os.path.exists(model_path):
            return jsonify({
                'error': 'í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.'
            }), 404
        
        # predict ìŠ¤í¬ë¦½íŠ¸ë¥¼ subprocessë¡œ ì‹¤í–‰ (ai_ml venv ì‚¬ìš©)
        predict_script_path = os.path.join(ai_ml_path, 'scripts', 'predict.py')
        predict_script_path = os.path.abspath(predict_script_path)
        
        if not os.path.exists(predict_script_path):
            return jsonify({'error': f'ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {predict_script_path}'}), 404
        
        # Python ê²½ë¡œ ì°¾ê¸° (ai_ml venv ìš°ì„ )
        python_path = 'python3'
        ai_ml_venv = os.path.join(ai_ml_path, 'venv', 'bin', 'python3')
        ai_ml_venv = os.path.abspath(ai_ml_venv)
        
        if os.path.exists(ai_ml_venv):
            python_path = ai_ml_venv
            print(f"âœ… ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: {python_path} {predict_script_path}")
        else:
            print(f"âš ï¸ ai_ml venvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ Python ì‚¬ìš©: {python_path}")
        
        # subprocessë¡œ ì‹¤í–‰
        import subprocess
        try:
            result = subprocess.run(
                [python_path, predict_script_path],
                cwd=ai_ml_path,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            # stderrì— ê²½ê³  ë©”ì‹œì§€ê°€ ìˆì„ ìˆ˜ ìˆìŒ (ë¬´ì‹œ)
            if result.stderr:
                print(f"ğŸ“‹ ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ stderr: {result.stderr[:500]}")
            
            if result.returncode != 0:
                error_msg = result.stderr or result.stdout
                print(f"âŒ ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜ (ì½”ë“œ: {result.returncode}): {error_msg}")
                return jsonify({'error': f'ì˜ˆì¸¡ ì‹¤í–‰ ì‹¤íŒ¨: {error_msg[:200]}'}), 500
            
            # JSON ê²°ê³¼ íŒŒì‹± (stdoutì˜ ë§ˆì§€ë§‰ ë¼ì¸ë§Œ í™•ì¸ - JSONë§Œ ì¶œë ¥ë˜ë„ë¡)
            import json
            stdout_lines = result.stdout.strip().split('\n')
            # ë§ˆì§€ë§‰ ë¼ì¸ì´ JSONì¸ì§€ í™•ì¸
            json_line = stdout_lines[-1] if stdout_lines else ''
            
            try:
                result_data = json.loads(json_line)
                if 'error' in result_data:
                    return jsonify(result_data), 500
                return jsonify(result_data)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì „ì²´ stdout í™•ì¸
                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. stdout ì „ì²´:")
                print(f"   {result.stdout[:500]}")
                # stdoutì—ì„œ JSON ë¶€ë¶„ ì°¾ê¸°
                for line in reversed(stdout_lines):
                    line = line.strip()
                    if line.startswith('{') and line.endswith('}'):
                        try:
                            result_data = json.loads(line)
                            if 'error' in result_data:
                                return jsonify(result_data), 500
                            return jsonify(result_data)
                        except json.JSONDecodeError:
                            continue
                
                return jsonify({'error': f'ì˜ˆì¸¡ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨. stdout: {result.stdout[:200]}'}), 500
                
        except subprocess.TimeoutExpired:
            return jsonify({'error': 'ì˜ˆì¸¡ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼'}), 500
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return jsonify({'error': str(e)}), 500
        
    except ImportError as e:
        print(f"âŒ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
        return jsonify({'error': f'AI ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ai_ml í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”: {str(e)}'}), 500
    except Exception as e:
        print(f"âŒ AI ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/ai/progress/<progress_type>', methods=['GET'])
def get_progress(progress_type):
    """ì§„í–‰ë¥  ì¡°íšŒ (augment ë˜ëŠ” train)"""
    try:
        import os
        import json
        
        backend_dir = os.path.dirname(os.path.abspath(__file__))
        simpac_dir = os.path.join(backend_dir, '..', '..')
        ai_ml_path = os.path.join(simpac_dir, 'ai_ml')
        
        if progress_type == 'augment':
            progress_file = os.path.join(ai_ml_path, 'data', 'augment_progress.json')
        elif progress_type == 'train':
            progress_file = os.path.join(ai_ml_path, 'data', 'train_progress.json')
        else:
            return jsonify({'error': 'Invalid progress type'}), 400
        
        progress_file = os.path.abspath(progress_file)
        
        if not os.path.exists(progress_file):
            return jsonify({
                'progress': 0,
                'stage': 'not_started',
                'message': 'ì•„ì§ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            })
        
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            
            # progress_dataì—ì„œ í•„ìš”í•œ í•„ë“œë§Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            result = {
                'progress': progress_data.get('progress', 0),
                'stage': progress_data.get('stage', 'unknown'),
                'message': progress_data.get('message', 'ì§„í–‰ ì¤‘...')
            }
            
            # ì˜ˆìƒ ì‹œê°„ì´ ìˆìœ¼ë©´ í¬í•¨
            if 'estimated_time_seconds' in progress_data:
                result['estimated_time_seconds'] = progress_data['estimated_time_seconds']
                result['estimated_time_minutes'] = progress_data.get('estimated_time_minutes', 
                                                                     progress_data['estimated_time_seconds'] / 60)
            
            # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ í¬í•¨
            if 'error' in progress_data:
                result['error'] = progress_data['error']
            
            return jsonify(result)
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return jsonify({
                'error': f'ì§„í–‰ë¥  íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}',
                'progress': 0,
                'stage': 'error',
                'message': 'ì§„í–‰ë¥  íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }), 500
        except Exception as e:
            print(f"âŒ ì§„í–‰ë¥  íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return jsonify({
                'error': str(e),
                'progress': 0,
                'stage': 'error',
                'message': f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }), 500
        
    except Exception as e:
        print(f"âŒ ì§„í–‰ë¥  ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5005)
